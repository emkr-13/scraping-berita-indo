{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Link 20\n"
     ]
    }
   ],
   "source": [
    "links=[]\n",
    "# jumlah Page yang diambil \n",
    "jumlah_index = 1\n",
    "\n",
    "for index in range(jumlah_index):\n",
    "    url = f\"https://www.tribunnews.com/2023/09?page={index+1}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Chrome/117.0.0.0'})\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        articles = soup.find_all('li', {\"class\": \"ptb15\"})\n",
    "        for article in articles:\n",
    "            header = article.find('h3', {\"class\": \"fbo f16\"})\n",
    "            link = header.find('a')['href']\n",
    "            links.append(link)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while fetching data from {url}: {e}\")\n",
    "\n",
    "print(\"Jumlah Link\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "author = []\n",
    "editor =[]\n",
    "date = []\n",
    "content = []\n",
    "\n",
    "for link in links:\n",
    "    url = link \n",
    "    hdr = {'User-Agent': 'Chrome/117.0.0.0'}\n",
    "    req = Request(url,headers=hdr)\n",
    "    page = urlopen(req)  \n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    # Title Berita\n",
    "    title_elem = soup.find('h1', {\"id\": \"arttitle\"})\n",
    "    if title_elem:\n",
    "        \n",
    "        title_text = title_elem.text.strip()\n",
    "        # print(title_text)\n",
    "    else:\n",
    "        title_text = \"Title not found\"\n",
    "    title.append(title_text)\n",
    "    \n",
    "    # Author Berita\n",
    "    author_elem = soup.find('div', {\"id\": \"penulis\"})\n",
    "    if author_elem:\n",
    "        # print(author_elem)\n",
    "        penulis = author_elem.find('a')\n",
    "        author_text =penulis.text.strip()\n",
    "    else:\n",
    "        author_text = \"Author not found\"\n",
    "    author.append(author_text)\n",
    "    \n",
    "    # Editor Berita\n",
    "    editor_elem = soup.find('div', {\"id\": \"editor\"})\n",
    "    \n",
    "    if editor_elem:\n",
    "        editors = editor_elem.find('a')\n",
    "        editor_text = editors.text.strip()\n",
    "    else:\n",
    "        editor_text = \"editor not found\"\n",
    "    editor.append(editor_text)\n",
    "    \n",
    "    # date berita\n",
    "    date_elem = soup.find('time', {\"class\": \"grey\"})\n",
    "    if date_elem:\n",
    "        date_text = date_elem.text.strip()\n",
    "    else:\n",
    "        date_text = \"Date not found\"\n",
    "    date.append(date_text)\n",
    "    \n",
    "    \n",
    "    # content berita\n",
    "    body_elem = soup.find('div', {\"class\": \"side-article txt-article multi-fontsize\"})\n",
    "\n",
    "    if body_elem:\n",
    "        content_elem = body_elem.find_all('p')\n",
    "        content_text = \"\"\n",
    "        for p in content_elem:\n",
    "            content_text += p.text.strip() + \"\\n\"\n",
    "            \n",
    "        if content_text.strip():\n",
    "            content.append(content_text)\n",
    "        else:\n",
    "            content.append(\"Content not found\")\n",
    "    else:\n",
    "        content.append(\"Content not found\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>editor</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nilai PTS Jeblok Guru Jadi Korban, Dibacok Hin...</td>\n",
       "      <td>Author not found</td>\n",
       "      <td>Hendra Gunawan</td>\n",
       "      <td>Senin, 25 September 2023 15:56 WIB</td>\n",
       "      <td>TRIBUNNEWS.COM, DEMAK - Seorang siswa Madrasah...</td>\n",
       "      <td>https://www.tribunnews.com/regional/2023/09/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Profil Syaiful Huda, Wasekjen PKB yang Jadi An...</td>\n",
       "      <td>Faryyanida Putwiliani</td>\n",
       "      <td>Daryono</td>\n",
       "      <td>Senin, 25 September 2023 15:55 WIB</td>\n",
       "      <td>TRIBUNNEWS.COM - Bacapres Anies Baswedan dan B...</td>\n",
       "      <td>https://www.tribunnews.com/mata-lokal-memilih/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kecelakaan Maut di Sampit, Siswi Kelas 5 SD Te...</td>\n",
       "      <td>Author not found</td>\n",
       "      <td>Eko Sutriyanto</td>\n",
       "      <td>Senin, 25 September 2023 15:54 WIB</td>\n",
       "      <td>Laporan Wartawan Tribun Kalteng Devita Maulina...</td>\n",
       "      <td>https://www.tribunnews.com/regional/2023/09/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buntut Aksi Anarkis Pengunjuk Rasa di Pohuwato...</td>\n",
       "      <td>Author not found</td>\n",
       "      <td>Erik S</td>\n",
       "      <td>Senin, 25 September 2023 15:54 WIB</td>\n",
       "      <td>TRIBUNNEWS.COM, GORONTALO- Polisi menetapkan l...</td>\n",
       "      <td>https://www.tribunnews.com/regional/2023/09/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Formasi PPPK Kemenperin 2023 untuk Lulusan SMK...</td>\n",
       "      <td>Widya Lisfianti</td>\n",
       "      <td>bunga pradipta p</td>\n",
       "      <td>Senin, 25 September 2023 15:52 WIB</td>\n",
       "      <td>TRIBUNNEWS.COM - Kementerian Perindustrian (Ke...</td>\n",
       "      <td>https://www.tribunnews.com/nasional/2023/09/25...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 author  \\\n",
       "0  Nilai PTS Jeblok Guru Jadi Korban, Dibacok Hin...       Author not found   \n",
       "1  Profil Syaiful Huda, Wasekjen PKB yang Jadi An...  Faryyanida Putwiliani   \n",
       "2  Kecelakaan Maut di Sampit, Siswi Kelas 5 SD Te...       Author not found   \n",
       "3  Buntut Aksi Anarkis Pengunjuk Rasa di Pohuwato...       Author not found   \n",
       "4  Formasi PPPK Kemenperin 2023 untuk Lulusan SMK...        Widya Lisfianti   \n",
       "\n",
       "             editor                                date  \\\n",
       "0    Hendra Gunawan  Senin, 25 September 2023 15:56 WIB   \n",
       "1           Daryono  Senin, 25 September 2023 15:55 WIB   \n",
       "2    Eko Sutriyanto  Senin, 25 September 2023 15:54 WIB   \n",
       "3            Erik S  Senin, 25 September 2023 15:54 WIB   \n",
       "4  bunga pradipta p  Senin, 25 September 2023 15:52 WIB   \n",
       "\n",
       "                                             content  \\\n",
       "0  TRIBUNNEWS.COM, DEMAK - Seorang siswa Madrasah...   \n",
       "1  TRIBUNNEWS.COM - Bacapres Anies Baswedan dan B...   \n",
       "2  Laporan Wartawan Tribun Kalteng Devita Maulina...   \n",
       "3  TRIBUNNEWS.COM, GORONTALO- Polisi menetapkan l...   \n",
       "4  TRIBUNNEWS.COM - Kementerian Perindustrian (Ke...   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.tribunnews.com/regional/2023/09/25...  \n",
       "1  https://www.tribunnews.com/mata-lokal-memilih/...  \n",
       "2  https://www.tribunnews.com/regional/2023/09/25...  \n",
       "3  https://www.tribunnews.com/regional/2023/09/25...  \n",
       "4  https://www.tribunnews.com/nasional/2023/09/25...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "        'title': title,\n",
    "        'author' : author,\n",
    "        'editor' : editor,\n",
    "        'date': date,\n",
    "        'content' : content,\n",
    "        'link' : links\n",
    "        }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempat save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to ./excel/tribunews_2023-09-25_16-00-06.xlsx\n"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'./excel/tribunews_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Buat Latihan dan pengecek\n",
    "# links=[]\n",
    "# # jumlah Page yang diambil \n",
    "# jumlah_index = 2\n",
    "# for index in range(jumlah_index):\n",
    "#     url = f\"https://www.tribunnews.com/2023/09?page={index+1}\"\n",
    "#     # print(url)  \n",
    "#     hdr = {'User-Agent': 'Chrome/117.0.0.0'}\n",
    "#     req = Request(url,headers=hdr)\n",
    "#     page = urlopen(req)\n",
    "#     soup = BeautifulSoup(page)\n",
    "#     articles = soup.find_all('li', {\"class\": \"ptb15\"})\n",
    "#     # print(articles)\n",
    "#     for article in articles:\n",
    "#             header = article.find('h3', {\"class\": \"fbo f16\"})\n",
    "#             link = header.find('a')['href']\n",
    "#             links.append(link)\n",
    "    \n",
    "# print(len(links))\n",
    "# print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rinanda DwiYuliawati\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.tribunnews.com/seleb/2023/09/25/lama-tak-muncul-di-layar-kaca-andi-arsyil-mengaku-tak-takut-dilupakan-oleh-fans-gak-butuh-validasi\"\n",
    "    # print(url)  \n",
    "hdr = {'User-Agent': 'Chrome/117.0.0.0'}\n",
    "req = Request(url,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "# title berita\n",
    "# articles = soup.find('h1', {\"id\": \"arttitle\"})\n",
    "# print(articles.text.strip())\n",
    "\n",
    "# authors berita\n",
    "# articles = soup.find('div', {\"id\": \"penulis\"})\n",
    "# penulis = articles.find('a')\n",
    "# print(penulis.text.strip())\n",
    "\n",
    "# editor berita\n",
    "# articles = soup.find('div', {\"id\": \"editor\"})\n",
    "# penulis = articles.find('a')\n",
    "# print(penulis.text.strip())\n",
    "\n",
    "# isi berita \n",
    "# articles = soup.find('div', {\"class\": \"side-article txt-article multi-fontsize\"})\n",
    "# body_elem = soup.find('div', {\"class\": \"side-article txt-article multi-fontsize\"})\n",
    "\n",
    "# if body_elem:\n",
    "#     content_elem = body_elem.find_all('p')\n",
    "#     content_text = \"\"\n",
    "#     for p in content_elem:\n",
    "#         content_text += p.text.strip() + \"\\n\"\n",
    "        \n",
    "#     if content_text.strip():\n",
    "#         content.append(content_text)\n",
    "#     else:\n",
    "#         content.append(\"Content not found\")\n",
    "# else:\n",
    "#     content.append(\"Content not found\")\n",
    "\n",
    "# print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
