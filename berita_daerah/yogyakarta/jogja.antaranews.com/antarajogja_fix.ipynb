{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import time\n",
    "from datetime import datetime\n",
    "from decouple import config\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links_news(yesterday,date, keywords,page_number):\n",
    "    # date = dt.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    # formatted_date = date.strftime(\"%d-%m-%Y\")\n",
    "    # print(formatted_date)\n",
    "\n",
    "    # onedaybefore = date - dt.timedelta(days=1)\n",
    "    # onedayafter_str = onedaybefore.strftime(\"%d-%m-%Y\")\n",
    "    # print(onedayafter_str)\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = f\"https://jogja.antaranews.com/search?q={keywords}&startDate={yesterday}&endDate={date}&page={page_number}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all('article',{\"class\": \"simple-post simple-big clearfix\"})\n",
    "\n",
    "    page_links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    print(f\"data{page_number} and url {url}\")\n",
    "    # logger.success({\n",
    "    #     \"message\": f\"Scraped {len(page_links)} links from page {page_number} when {date}\"\n",
    "    #     })\n",
    "    \n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_link_per_day(date, keywords,max_threads=5):\n",
    "    page_number=1\n",
    "    page_links = None\n",
    "    date = dt.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    formatted_date = date.strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    yesterday = date - dt.timedelta(days=1)\n",
    "    yesterday = yesterday.strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    page_links= scrape_links_news(yesterday,formatted_date, keywords,page_number)\n",
    "\n",
    "\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 and url https://jogja.antaranews.com/search?q=jokowi&startDate=20-11-2023&endDate=21-11-2023&page=1\n"
     ]
    }
   ],
   "source": [
    "link=scrape_link_per_day(\"2023-11-21\",'jokowi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://jogja.antaranews.com/berita/648012/pdip-dukung-pemerintahan-jokowi']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url,max_retries=2):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "            try:\n",
    "                headers = {\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "                }\n",
    "                response = requests.get(url, headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                    # element Title \n",
    "                    title_elem = soup.find('h1',{\"class\": \"post-title\"})\n",
    "                    title_text = title_elem.text.strip() if title_elem else \"Title not found\"\n",
    "                    # element Date\n",
    "                    date_elem = soup.find('span', {\"class\": \"article-date\"})\n",
    "                    date_text = date_elem.text.strip() if date_elem else \"Date not found\"\n",
    "                    # locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "                    month_names_id = {\n",
    "                        'Januari': 'January',\n",
    "                        'Februari': 'February',\n",
    "                        'Maret': 'March',\n",
    "                        'April': 'April',\n",
    "                        'Mei': 'May',\n",
    "                        'Juni': 'June',\n",
    "                        'Juli': 'July',\n",
    "                        'Agustus': 'August',\n",
    "                        'September': 'September',\n",
    "                        'Oktober': 'October',\n",
    "                        'November': 'November',\n",
    "                        'Desember': 'December',\n",
    "                    }\n",
    "                    for ind, eng in month_names_id.items():\n",
    "                            date_text = date_text.replace(ind, eng)\n",
    "                    day_names_id = {\n",
    "                                    'Senin': 'Monday',\n",
    "                                    'Selasa': 'Tuesday',\n",
    "                                    'Rabu': 'Wednesday',\n",
    "                                    'Kamis': 'Thursday',\n",
    "                                    'Jumat': 'Friday',\n",
    "                                    'Sabtu': 'Saturday',\n",
    "                                    'Minggu': 'Sunday'\n",
    "                                }\n",
    "                    for ind, eng in day_names_id.items():\n",
    "                                date_text = date_text.replace(ind, eng)\n",
    "                    # locale.setlocale(locale.LC_TIME, 'id_ID')\n",
    "                    date_obj = datetime.strptime(date_text, '%A, %d %B %Y %H:%M %Z')\n",
    "                    formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "                    body_elem = soup.find('div', {\"class\": \"post-content clearfix font17\"})\n",
    "                    if body_elem:\n",
    "                        content_text = body_elem.text\n",
    "                        content_text = content_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "                        content_text = ' '.join(content_text.split())\n",
    "                    else:\n",
    "                        content_text =\"Content not found\"\n",
    "\n",
    "                    return {\n",
    "                        'title': title_text,\n",
    "                        'date': formatted_date,\n",
    "                        'content': content_text,\n",
    "                        'link': url\n",
    "                    }\n",
    "                else:\n",
    "                    # logger.error(\n",
    "                    #     {\"message\": f\"Failed to retrieve data from {url}: Status Code {response.status_code}\"}\n",
    "                    #     )\n",
    "                    print('hellow')\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # logger.error({\n",
    "                #     \"message\":f\"Error fetching URL '{url}': {e}\"\n",
    "                # })\n",
    "                print(e)\n",
    "            except Exception as e:\n",
    "                # logger.error({\n",
    "                #     \"message\":f\"Error processing URL '{url}': {e}\"\n",
    "                # })\n",
    "                print(e)\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                # logger.info({\n",
    "                #     \"message\":f\"Retrying {url} (Attempt {retries}/{max_retries})\"\n",
    "                # })\n",
    "                print(f\"Retrying {url} (Attempt {retries}/{max_retries})\")\n",
    "                time.sleep(5)  # You can adjust the delay as needed\n",
    "    return None       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://jogja.antaranews.com/berita/648012/pdip-dukung-pemerintahan-jokowi'\n",
    "cek=scrape_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'PDIP dukung Pemerintahan Jokowi', 'date': '2023-11-20', 'content': 'Jakarta (ANTARA) - Ketua DPP PDI Perjuangan Puan Maharani menegaskan partainya tetap mendukung pemerintahan Joko Widodo dan Ma\\'ruf Amin.\"Pak Jokowi merupakan presiden dari PDIP, yang kemarin kami usung dan kami dukung. Jadi posisi sampai hari ini masih seperti itu,\" katanya di Kompleks Parlemen, Senayan, Jakarta, Senin.Dia menjelaskan dari awal posisi PDIP sampai saat ini maupun sebelum masa pemilu selalu menyampaikan kritik kepada pemerintah, baik secara langsung atau tidak langsung. Tujuannya, bagaimana kinerja pemerintah bisa terus memperbaiki diri.\"Sehingga memang sebanyak-banyaknya, sebesar-besarnya adalah untuk kepentingan rakyat,\" ujarnya.Selain itu, kata Puan, dia sebagai Ketua DPR RI biasanya secara berkala bertemu Presiden Jokowi untuk membicarakan hal-hal yang terkait isu aktual.\"Bisa juga sebagai bukan posisi presiden dan Ketua DPR, Namun, keluarga atau orang yang sudah sama-sama mengenal,\" ungkapnya.Berita ini telah tayang di Antaranews.com dengan judul: Puan Maharani tegaskan PDIP dukung pemerintahan Jokowi', 'link': 'https://jogja.antaranews.com/berita/648012/pdip-dukung-pemerintahan-jokowi'}\n"
     ]
    }
   ],
   "source": [
    "print(cek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
