{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_index = 1\n",
    "threads_link = []\n",
    "links = []\n",
    "results = []\n",
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(page_number):\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = f\"https://jatimnow.com/category/politik/{page_number}\"\n",
    "    response = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all('h2',{\"class\": \"entry-title\"})\n",
    "    \n",
    "    page_links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    \n",
    "    print(f\"Scraped {len(page_links)} links from page {page_number}\")\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 8 links from page 1\n",
      "Total Links: 8\n"
     ]
    }
   ],
   "source": [
    "for page_number in range(1, jumlah_index + 1):\n",
    "    thread = threading.Thread(target=lambda p=page_number: links.extend(scrape_links(p)))\n",
    "    thread.start()\n",
    "    threads_link.append(thread)\n",
    "\n",
    "for thread in threads_link:\n",
    "    thread.join()\n",
    "print(\"Total Links:\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url):\n",
    "    try:\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url,headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')        \n",
    "            # Judul Berita\n",
    "            title_elem = soup.find('h1',{\"class\": \"entry-title\"})\n",
    "            if title_elem:\n",
    "                title_text = title_elem.text\n",
    "            else:\n",
    "                title_text = \"Title not found\"\n",
    "            # Author berita\n",
    "            author_elem =soup.find('span', {\"class\": \"cat-links-content\"})  \n",
    "            if author_elem:\n",
    "                author_text = author_elem.text.split(':')[2]\n",
    "            else:\n",
    "                author_text = \"Author not found\"     \n",
    "            # tanggal berita\n",
    "            date_elem = soup.find('time', {\"itemprop\": \"datePublished\"})\n",
    "            if date_elem:\n",
    "                date_text = date_elem.text\n",
    "            else:\n",
    "                date_text = \"Date not found\"\n",
    "            #     # Category berita\n",
    "            # category_elements = soup.find('span', {\"class\": \"kanal\"})\n",
    "            # if category_elements:\n",
    "            #     category_text= category_elements.text\n",
    "            # else:\n",
    "            category_text = \"Category not found\"\n",
    "            #     # Content Berita\n",
    "            body_elem = soup.find('div', {\"class\": \"entry-content entry-content-single clearfix\"})\n",
    "            \n",
    "            if body_elem:\n",
    "                content_elem = body_elem.find_all('p')\n",
    "                content_text = \"\"\n",
    "                for p in content_elem:\n",
    "                    content_text += p.text.strip() + \"\\n\"\n",
    "                \n",
    "                if content_text.strip():\n",
    "                    content_text=content_text\n",
    "                else:\n",
    "                    content_text =\"Content not found\"\n",
    "            else:\n",
    "                content_text =\"Content not found\"\n",
    "\n",
    "            results.append({'title': title_text,\n",
    "                            'author' : author_text,\n",
    "                            'category':category_text,\n",
    "                            'date': date_text,\n",
    "                            'content' : content_text,\n",
    "                            'region':'jatim',\n",
    "                            'link' : url})\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from {url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL '{url}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL '{url}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    thread = threading.Thread(target=scrape_url, args=(url,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ribuan Relawan Adies Kadir Lantunkan Selawat u...</td>\n",
       "      <td>Ni'am Kurniawan</td>\n",
       "      <td>Category not found</td>\n",
       "      <td>Minggu, 24 Sep 2023 09:25 WIB</td>\n",
       "      <td>jatimnow.com - Lantunan selawat menggema dari ...</td>\n",
       "      <td>jatim</td>\n",
       "      <td>https://jatimnow.com/baca-61867-ribuan-relawan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 Partai Parlemener Usung Petahana di Dapil 2 ...</td>\n",
       "      <td>Ahaddiini HM</td>\n",
       "      <td>Category not found</td>\n",
       "      <td>Jumat, 22 Sep 2023 14:53 WIB</td>\n",
       "      <td>jatimnow.com - Dari 18 partai dengan daftar ca...</td>\n",
       "      <td>jatim</td>\n",
       "      <td>https://jatimnow.com/baca-61822-5-partai-parle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keluarga Tambak Beras Doa Bersama untuk Yenny ...</td>\n",
       "      <td>Ni'am Kurniawan</td>\n",
       "      <td>Category not found</td>\n",
       "      <td>Minggu, 24 Sep 2023 07:03 WIB</td>\n",
       "      <td>jatimnow.com - Puluhan gus keluarga besar Ponp...</td>\n",
       "      <td>jatim</td>\n",
       "      <td>https://jatimnow.com/baca-61860-keluarga-tamba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khofifah, Emil dan Fauzi Disebut Memiliki Kans...</td>\n",
       "      <td>Ni'am Kurniawan</td>\n",
       "      <td>Category not found</td>\n",
       "      <td>Jumat, 22 Sep 2023 20:55 WIB</td>\n",
       "      <td>jatimnow.com - Direktur Lembaga riset ARCI Bai...</td>\n",
       "      <td>jatim</td>\n",
       "      <td>https://jatimnow.com/baca-61838-khofifah-emil-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relawan Ganjar Pasang Lampu PJU di Bojonegoro</td>\n",
       "      <td>Misbahul Munir</td>\n",
       "      <td>Category not found</td>\n",
       "      <td>Minggu, 24 Sep 2023 16:19 WIB</td>\n",
       "      <td>jatimnow.com - Relawan Orang Muda Ganjar (OMG)...</td>\n",
       "      <td>jatim</td>\n",
       "      <td>https://jatimnow.com/baca-61881-relawan-ganjar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title             author  \\\n",
       "0  Ribuan Relawan Adies Kadir Lantunkan Selawat u...   Ni'am Kurniawan    \n",
       "1  5 Partai Parlemener Usung Petahana di Dapil 2 ...      Ahaddiini HM    \n",
       "2  Keluarga Tambak Beras Doa Bersama untuk Yenny ...   Ni'am Kurniawan    \n",
       "3  Khofifah, Emil dan Fauzi Disebut Memiliki Kans...   Ni'am Kurniawan    \n",
       "4      Relawan Ganjar Pasang Lampu PJU di Bojonegoro    Misbahul Munir    \n",
       "\n",
       "             category                            date  \\\n",
       "0  Category not found  Minggu, 24 Sep 2023 09:25 WIB    \n",
       "1  Category not found   Jumat, 22 Sep 2023 14:53 WIB    \n",
       "2  Category not found  Minggu, 24 Sep 2023 07:03 WIB    \n",
       "3  Category not found   Jumat, 22 Sep 2023 20:55 WIB    \n",
       "4  Category not found  Minggu, 24 Sep 2023 16:19 WIB    \n",
       "\n",
       "                                             content region  \\\n",
       "0  jatimnow.com - Lantunan selawat menggema dari ...  jatim   \n",
       "1  jatimnow.com - Dari 18 partai dengan daftar ca...  jatim   \n",
       "2  jatimnow.com - Puluhan gus keluarga besar Ponp...  jatim   \n",
       "3  jatimnow.com - Direktur Lembaga riset ARCI Bai...  jatim   \n",
       "4  jatimnow.com - Relawan Orang Muda Ganjar (OMG)...  jatim   \n",
       "\n",
       "                                                link  \n",
       "0  https://jatimnow.com/baca-61867-ribuan-relawan...  \n",
       "1  https://jatimnow.com/baca-61822-5-partai-parle...  \n",
       "2  https://jatimnow.com/baca-61860-keluarga-tamba...  \n",
       "3  https://jatimnow.com/baca-61838-khofifah-emil-...  \n",
       "4  https://jatimnow.com/baca-61881-relawan-ganjar...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(len(results))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'../../tempat_hasil_daerah/jatim_now_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
