{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_index = 1\n",
    "threads_link = []\n",
    "links = []\n",
    "results = []\n",
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(page_number):\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = f\"https://radarsemarang.jawapos.com/jateng?page={page_number}\"\n",
    "    response = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all('h2',{\"class\": \"latest__title\"})\n",
    "    \n",
    "    page_links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    \n",
    "    print(f\"Scraped {len(page_links)} links from page {page_number}\")\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 20 links from page 1\n",
      "Total Links: 20\n"
     ]
    }
   ],
   "source": [
    "for page_number in range(1, jumlah_index + 1):\n",
    "    thread = threading.Thread(target=lambda p=page_number: links.extend(scrape_links(p)))\n",
    "    thread.start()\n",
    "    threads_link.append(thread)\n",
    "\n",
    "for thread in threads_link:\n",
    "    thread.join()\n",
    "print(\"Total Links:\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_url(url):\n",
    "    try:\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url,headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')        \n",
    "            # Judul Berita\n",
    "            title_elem = soup.find('h1',{\"class\": \"read__title\"})\n",
    "            if title_elem:\n",
    "                title_text = title_elem.text\n",
    "            else:\n",
    "                title_text = \"Title not found\"\n",
    "            # Author berita\n",
    "            author_elem = soup.find('div', {\"class\": \"read__info__author\"})\n",
    "            if author_elem:\n",
    "                author_text = author_elem.find('a')\n",
    "                author_text = author_text.text\n",
    "            else:\n",
    "                author_text = \"Author not found\"     \n",
    "            # tanggal berita\n",
    "            date_elem = soup.find('div', {\"class\": \"read__info__date\"})\n",
    "            if date_elem:\n",
    "                date_text = date_elem.text\n",
    "            else:\n",
    "                date_text = \"Date not found\"\n",
    "            #     # Category berita\n",
    "            category_elements = soup.find_all('a', {\"class\": \"breadcrumb__link\"})\n",
    "            if category_elements:\n",
    "                category_text= category_elements[1].text\n",
    "            else:\n",
    "                category_text = \"Category not found\"\n",
    "            #     # Content Berita\n",
    "            body_elem = soup.find('article', {\"class\": \"read__content clearfix\"})\n",
    "            \n",
    "            if body_elem:\n",
    "                content_elem = body_elem.find_all('div')\n",
    "                content_text = \"\"\n",
    "                for p in content_elem:\n",
    "                    content_text += p.text.strip() + \"\\n\"\n",
    "                \n",
    "                if content_text.strip():\n",
    "                    content_text=content_text\n",
    "                else:\n",
    "                    content_text =\"Content not found\"\n",
    "            else:\n",
    "                content_text =\"Content not found\"\n",
    "\n",
    "            results.append({'title': title_text,\n",
    "                            'author' : author_text,\n",
    "                            'category':category_text,\n",
    "                            'date': date_text,\n",
    "                            'content' : content_text,\n",
    "                            'region':'jateng',\n",
    "                            'link' : url})\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from {url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL '{url}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL '{url}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data from https://radarsemarang.jawapos.com/jateng/723012596/ferry-wawan-cahyono-dorong-percepatan-penanganan-lonjakan-kenaikan-harga-beras-di-jateng\n"
     ]
    }
   ],
   "source": [
    "for url in links:\n",
    "    thread = threading.Thread(target=scrape_url, args=(url,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pelaku Pembunuhan Gadis Berseragam Pramuka Se...</td>\n",
       "      <td>Lutfi Hanafi</td>\n",
       "      <td>Pemalang</td>\n",
       "      <td>\\n                                    - Senin,...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/pemalang/723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Koperasi Dilibatkan dalam Hilirisasi Bawang M...</td>\n",
       "      <td>Lutfi Hanafi</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Senin,...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daftar Tujuh Daerah di Jateng yang Paling Raw...</td>\n",
       "      <td>Rofik Syarif Ghirinda Putra</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Selasa...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindari Penyalahgunaan, 341.043 Arsip Fisik S...</td>\n",
       "      <td>Ida Fadilah</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Senin,...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kemenkumham Jateng Gelar Supervisi Layanan Te...</td>\n",
       "      <td>Ida Fadilah</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Jumat,...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72301...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Pelaku Pembunuhan Gadis Berseragam Pramuka Se...   \n",
       "1   Koperasi Dilibatkan dalam Hilirisasi Bawang M...   \n",
       "2   Daftar Tujuh Daerah di Jateng yang Paling Raw...   \n",
       "3   Hindari Penyalahgunaan, 341.043 Arsip Fisik S...   \n",
       "4   Kemenkumham Jateng Gelar Supervisi Layanan Te...   \n",
       "\n",
       "                        author  category  \\\n",
       "0                 Lutfi Hanafi  Pemalang   \n",
       "1                 Lutfi Hanafi    Jateng   \n",
       "2  Rofik Syarif Ghirinda Putra    Jateng   \n",
       "3                  Ida Fadilah    Jateng   \n",
       "4                  Ida Fadilah    Jateng   \n",
       "\n",
       "                                                date            content  \\\n",
       "0  \\n                                    - Senin,...  Content not found   \n",
       "1  \\n                                    - Senin,...  Content not found   \n",
       "2  \\n                                    - Selasa...  Content not found   \n",
       "3  \\n                                    - Senin,...  Content not found   \n",
       "4  \\n                                    - Jumat,...  Content not found   \n",
       "\n",
       "   region                                               link  \n",
       "0  jateng  https://radarsemarang.jawapos.com/pemalang/723...  \n",
       "1  jateng  https://radarsemarang.jawapos.com/jateng/72297...  \n",
       "2  jateng  https://radarsemarang.jawapos.com/jateng/72295...  \n",
       "3  jateng  https://radarsemarang.jawapos.com/jateng/72295...  \n",
       "4  jateng  https://radarsemarang.jawapos.com/jateng/72301...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(len(results))\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
