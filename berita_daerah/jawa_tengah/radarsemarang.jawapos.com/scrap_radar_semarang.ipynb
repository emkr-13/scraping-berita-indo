{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_index = 1\n",
    "threads_link = []\n",
    "links = []\n",
    "results = []\n",
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(page_number):\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = f\"https://radarsemarang.jawapos.com/jateng?page={page_number}\"\n",
    "    response = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all('h2',{\"class\": \"latest__title\"})\n",
    "    \n",
    "    page_links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    \n",
    "    print(f\"Scraped {len(page_links)} links from page {page_number}\")\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 20 links from page 1\n",
      "Total Links: 20\n"
     ]
    }
   ],
   "source": [
    "for page_number in range(1, jumlah_index + 1):\n",
    "    thread = threading.Thread(target=lambda p=page_number: links.extend(scrape_links(p)))\n",
    "    thread.start()\n",
    "    threads_link.append(thread)\n",
    "\n",
    "for thread in threads_link:\n",
    "    thread.join()\n",
    "print(\"Total Links:\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url):\n",
    "    try:\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url,headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')        \n",
    "            # Judul Berita\n",
    "            title_elem = soup.find('h1',{\"class\": \"read__title\"})\n",
    "            if title_elem:\n",
    "                title_text = title_elem.text\n",
    "            else:\n",
    "                title_text = \"Title not found\"\n",
    "            # Author berita\n",
    "            author_elem = soup.find('div', {\"class\": \"read__info__author\"})\n",
    "            if author_elem:\n",
    "                author_text = author_elem.find('a')\n",
    "                author_text = author_text.text\n",
    "            else:\n",
    "                author_text = \"Author not found\"     \n",
    "            # tanggal berita\n",
    "            date_elem = soup.find('div', {\"class\": \"read__info__date\"})\n",
    "            if date_elem:\n",
    "                date_text = date_elem.text\n",
    "            else:\n",
    "                date_text = \"Date not found\"\n",
    "            #     # Category berita\n",
    "            category_elements = soup.find_all('a', {\"class\": \"breadcrumb__link\"})\n",
    "            if category_elements:\n",
    "                category_text= category_elements[1].text\n",
    "            else:\n",
    "                category_text = \"Category not found\"\n",
    "            #     # Content Berita\n",
    "            body_elem = soup.find('article', {\"class\": \"read__content clearfix\"})\n",
    "            \n",
    "            if body_elem:\n",
    "                content_elem = body_elem.find_all('div')\n",
    "                content_text = \"\"\n",
    "                for p in content_elem:\n",
    "                    content_text += p.text.strip() + \"\\n\"\n",
    "                \n",
    "                if content_text.strip():\n",
    "                    content_text=content_text\n",
    "                else:\n",
    "                    content_text =\"Content not found\"\n",
    "            else:\n",
    "                content_text =\"Content not found\"\n",
    "\n",
    "            results.append({'title': title_text,\n",
    "                            'author' : author_text,\n",
    "                            'category':category_text,\n",
    "                            'date': date_text,\n",
    "                            'content' : content_text,\n",
    "                            'region':'jateng',\n",
    "                            'link' : url})\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from {url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL '{url}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL '{url}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data from https://radarsemarang.jawapos.com/jateng/723012596/ferry-wawan-cahyono-dorong-percepatan-penanganan-lonjakan-kenaikan-harga-beras-di-jateng\n"
     ]
    }
   ],
   "source": [
    "for url in links:\n",
    "    thread = threading.Thread(target=scrape_url, args=(url,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resmi Dilantik Jadi Pj Bupati Temanggung, Har...</td>\n",
       "      <td>Khafifah Arini Putri</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Minggu...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Operasi Sikat Jaran Candi 2023, Polda Jateng ...</td>\n",
       "      <td>Muhammad Hariyanto</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Minggu...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pelaku Pembunuhan Gadis Berseragam Pramuka Se...</td>\n",
       "      <td>Lutfi Hanafi</td>\n",
       "      <td>Pemalang</td>\n",
       "      <td>\\n                                    - Senin,...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/pemalang/723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714 Desa di Jateng Krisis Air Bersih, Blora d...</td>\n",
       "      <td>Khafifah Arini Putri</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Rabu, ...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akan Dibuka BRT Trans Jateng Koridor Baru Pan...</td>\n",
       "      <td>Miftahul A’la</td>\n",
       "      <td>Jateng</td>\n",
       "      <td>\\n                                    - Senin,...</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>jateng</td>\n",
       "      <td>https://radarsemarang.jawapos.com/jateng/72297...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                author  \\\n",
       "0   Resmi Dilantik Jadi Pj Bupati Temanggung, Har...  Khafifah Arini Putri   \n",
       "1   Operasi Sikat Jaran Candi 2023, Polda Jateng ...    Muhammad Hariyanto   \n",
       "2   Pelaku Pembunuhan Gadis Berseragam Pramuka Se...          Lutfi Hanafi   \n",
       "3   714 Desa di Jateng Krisis Air Bersih, Blora d...  Khafifah Arini Putri   \n",
       "4   Akan Dibuka BRT Trans Jateng Koridor Baru Pan...         Miftahul A’la   \n",
       "\n",
       "   category                                               date  \\\n",
       "0    Jateng  \\n                                    - Minggu...   \n",
       "1    Jateng  \\n                                    - Minggu...   \n",
       "2  Pemalang  \\n                                    - Senin,...   \n",
       "3    Jateng  \\n                                    - Rabu, ...   \n",
       "4    Jateng  \\n                                    - Senin,...   \n",
       "\n",
       "             content  region  \\\n",
       "0  Content not found  jateng   \n",
       "1  Content not found  jateng   \n",
       "2  Content not found  jateng   \n",
       "3  Content not found  jateng   \n",
       "4  Content not found  jateng   \n",
       "\n",
       "                                                link  \n",
       "0  https://radarsemarang.jawapos.com/jateng/72301...  \n",
       "1  https://radarsemarang.jawapos.com/jateng/72297...  \n",
       "2  https://radarsemarang.jawapos.com/pemalang/723...  \n",
       "3  https://radarsemarang.jawapos.com/jateng/72295...  \n",
       "4  https://radarsemarang.jawapos.com/jateng/72297...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(len(results))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'../../tempat_hasil_daerah/radar_semarang_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
