{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from datetime import datetime\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_link_per_day(date):\n",
    "    headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "        }\n",
    "    url = f\"https://www.tempo.co/indeks/{date}/nasional\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    body = soup.find('main', {\"class\": \"main-left\"})\n",
    "    articles= body.findAll('h2', {\"class\": \"title\"})\n",
    "    page_links=[]\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    print(f\"Scraped {len(page_links)} links when date {date}\")\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 72 links when date 2023-11-01\n"
     ]
    }
   ],
   "source": [
    "all_link=scrape_link_per_day('2023-11-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url,max_retries=3):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "            try:\n",
    "                headers = {\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "                }\n",
    "                response = requests.get(url, headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                    # Extract data from the web page\n",
    "                    title_elem = soup.find('h1', {\"class\": \"title margin-bottom-sm\"})\n",
    "                    title_text = title_elem.text.strip() if title_elem else \"Title not found\"\n",
    "\n",
    "                    date_elem = soup.find('p', {\"class\": \"date margin-bottom-sm\"})\n",
    "                    date_text = date_elem.text.strip() if date_elem else \"Date not found\"\n",
    "                    \n",
    "                    date_part = ' '.join(date_text.split(',')[1:]).strip()\n",
    "                    date_object = parser.parse(date_part)\n",
    "                    formatted_date = date_object.strftime('%Y-%m-%d')\n",
    "\n",
    "                    body_elem = soup.find('div', {\"class\": \"detail-konten\"})\n",
    "                    if body_elem:\n",
    "                        content_elem = body_elem.find_all('p')\n",
    "                        content_text = \"\\n\".join(p.text.strip() for p in content_elem)\n",
    "                        content_text = content_text.replace('\\n', ' ')\n",
    "                    else:\n",
    "                        content_text = \"Content not found\"\n",
    "\n",
    "                    return {\n",
    "                        'title': title_text,\n",
    "                        'date': formatted_date,\n",
    "                        'content': content_text,\n",
    "                        'link': url\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve data from {url}: Status Code {response.status_code}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching URL '{url}': {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL '{url}': {e}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(f\"Retrying {url} (Attempt {retries}/{max_retries})\")\n",
    "                time.sleep(5)  # You can adjust the delay as needed\n",
    "    return None         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://nasional.tempo.co/read/1791540/politikus-golkar-sebut-usulan-hak-angket-masinton-hanya-gimik-politik-untuk-degradasi-prabowo-gibran'\n",
    "cek_hasil=scrape_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Politikus Golkar Sebut Usulan Hak Angket Masinton Hanya Gimik Politik untuk Degradasi Prabowo-Gibran', 'date': '2023-11-01', 'content': 'TEMPO.CO, Jakarta - Ketua Badan Pemenangan Pemilu Partai Golkar Maman Abdurahman menanggapi usulan politikus PDIP Masinton Pasaribu untuk mengusulkan hak angket DPR terhadap Mahkamah Konstitusi atau MK. Menurut Maman, usulan Masinton itu tak akan berimplikasi apa pun terhadap putusan MK soal batas usia capres-cawapres. \"Saya pikir, terus kalau pun itu terwujud ada pengusulan hak angket, terus implikasinya juga apa? Kan nggak ada juga,\" kata dia saat ditemui di Kompleks Stadion Gelora Bung Karno, Jakarta Pusat, Rabu, 1 November 2023. Baca Juga: UM Surabaya Siap Gelar Uji Publik Pasangan Prabowo-Gibran, Ini Daftar Panelisnya Sebelumnya, dalam Rapat Paripurna Masa Sidang ke-8 DPR RI, Senin, 31 Oktober 2023, Masinton menyampaikan pendapatnya agar Dewan mengajukan hak angket untuk putusan MK soal batas usia capres-cawapres. Menurut Maman, apa yang diusulkan Masinton merupakan bagian dari hak konstitusi seorang anggota dewan di parlemen. Namun, dia menilai manuver Masinton itu hanya bagian dari gimik politik untuk membangun opini publik. \"Mendegradasi imej dari pak Prabowo dan mas Gibran,\" katanya. Baca Juga: Cerita Prabowo Jenguk Luhut di Singapura: Beliau Sudah Pulih, Ingin Segera Bekerja Maman mengatakan, dalam 3 bulan ke depan semua orang akan berjoget-joget terkait dinamika politik terkini. Ihwal dinamika politik apa pun, kata Maman, akan dimainkan. \"Jadi semua yang joget pasti akan melakukannya, tarian apa juga akan dimainkan. Jadi, kami melihatnya dalam konteks itu saja. Saya pikir silakan saja, itu kan menjadi haknya sahabat saya mas Masinton,\" kata dia. Anggota Komisi VII DPR itu mengatakan, Golkar menghormati upaya Masinton. Dan upaya hak angket bagian dari dinamika politik. \"Partai Golkar dan teman-teman fraksi lainnya pada posisi yang menganggap apa yang terjadi ini, ini adalah bagian dari semua proses dinamika politik dan wajar-wajar saja,\" katanya. Maman mengatakan terlepas kencangnya isu hak angket, Partai Golkar lebih fokus pada bagaimana pemenangan Prabowo-Gibran di Pilpres 2024. \"Fokus kami satu saja, bagaimana caranya turun ke bawah menemui masyarakat menyampaikan ke masyarakat bahwa ini loh sosok seorang Prabowo dan Gibran,\" katanya. Pilihan Editor:\\xa0Jimly Asshiddiqie Dukung DPR Ajukan Hak Angket Terhadap MK', 'link': 'https://nasional.tempo.co/read/1791540/politikus-golkar-sebut-usulan-hak-angket-masinton-hanya-gimik-politik-untuk-degradasi-prabowo-gibran'}\n"
     ]
    }
   ],
   "source": [
    "print(cek_hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
