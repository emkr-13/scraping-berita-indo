{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_index = 100\n",
    "threads_link = []\n",
    "links = []\n",
    "results = []\n",
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(page_number):\n",
    "    url = f\"https://www.cnbcindonesia.com/indeks/{page_number}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all('article')\n",
    "    \n",
    "    page_links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    \n",
    "    print(f\"Scraped {len(page_links)} links from page {page_number}\")\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 12 links from page 5\n",
      "Scraped 12 links from page 13\n",
      "Scraped 12 links from page 3\n",
      "Scraped 12 links from page 1\n",
      "Scraped 12 links from page 2\n",
      "Scraped 12 links from page 4\n",
      "Scraped 12 links from page 15\n",
      "Scraped 12 links from page 14\n",
      "Scraped 12 links from page 6\n",
      "Scraped 12 links from page 22\n",
      "Scraped 12 links from page 7\n",
      "Scraped 12 links from page 8\n",
      "Scraped 12 links from page 10\n",
      "Scraped 12 links from page 11\n",
      "Scraped 12 links from page 20\n",
      "Scraped 12 links from page 12\n",
      "Scraped 12 links from page 26\n",
      "Scraped 12 links from page 17\n",
      "Scraped 12 links from page 9\n",
      "Scraped 12 links from page 16\n",
      "Scraped 12 links from page 24\n",
      "Scraped 12 links from page 30\n",
      "Scraped 12 links from page 19\n",
      "Scraped 12 links from page 46\n",
      "Scraped 12 links from page 25\n",
      "Scraped 12 links from page 18\n",
      "Scraped 12 links from page 29\n",
      "Scraped 12 links from page 43\n",
      "Scraped 12 links from page 36\n",
      "Scraped 12 links from page 41\n",
      "Scraped 12 links from page 32\n",
      "Scraped 12 links from page 47\n",
      "Scraped 12 links from page 37\n",
      "Scraped 12 links from page 48\n",
      "Scraped 12 links from page 54\n",
      "Scraped 12 links from page 27\n",
      "Scraped 12 links from page 28\n",
      "Scraped 12 links from page 40\n",
      "Scraped 12 links from page 34\n",
      "Scraped 12 links from page 60\n",
      "Scraped 12 links from page 75\n",
      "Scraped 12 links from page 49\n",
      "Scraped 12 links from page 57\n",
      "Scraped 12 links from page 23\n",
      "Scraped 12 links from page 64\n",
      "Scraped 12 links from page 85\n",
      "Scraped 12 links from page 84\n",
      "Scraped 12 links from page 71\n",
      "Scraped 12 links from page 96\n",
      "Scraped 12 links from page 63\n",
      "Scraped 12 links from page 51\n",
      "Scraped 12 links from page 74\n",
      "Scraped 12 links from page 92\n",
      "Scraped 12 links from page 89\n",
      "Scraped 12 links from page 62\n",
      "Scraped 12 links from page 31\n",
      "Scraped 12 links from page 94\n",
      "Scraped 12 links from page 53\n",
      "Scraped 12 links from page 82\n",
      "Scraped 12 links from page 44\n",
      "Scraped 12 links from page 86\n",
      "Scraped 12 links from page 78\n",
      "Scraped 12 links from page 55\n",
      "Scraped 12 links from page 52\n",
      "Scraped 12 links from page 99\n",
      "Scraped 12 links from page 67\n",
      "Scraped 12 links from page 56\n",
      "Scraped 12 links from page 58\n",
      "Scraped 12 links from page 90\n",
      "Scraped 12 links from page 68\n",
      "Scraped 12 links from page 73\n",
      "Scraped 12 links from page 88\n",
      "Scraped 12 links from page 80\n",
      "Scraped 12 links from page 65\n",
      "Scraped 12 links from page 95\n",
      "Scraped 12 links from page 42\n",
      "Scraped 12 links from page 21\n",
      "Scraped 12 links from page 69\n",
      "Scraped 12 links from page 59\n",
      "Scraped 12 links from page 79\n",
      "Scraped 12 links from page 70\n",
      "Scraped 12 links from page 50\n",
      "Scraped 12 links from page 91\n",
      "Scraped 12 links from page 66\n",
      "Scraped 12 links from page 72\n",
      "Scraped 12 links from page 100\n",
      "Scraped 12 links from page 93\n",
      "Scraped 12 links from page 38\n",
      "Scraped 12 links from page 97\n",
      "Scraped 12 links from page 77\n",
      "Scraped 12 links from page 35\n",
      "Scraped 12 links from page 33\n",
      "Scraped 12 links from page 76\n",
      "Scraped 12 links from page 61\n",
      "Scraped 12 links from page 45\n",
      "Scraped 12 links from page 81\n",
      "Scraped 12 links from page 83\n",
      "Scraped 12 links from page 87\n",
      "Scraped 12 links from page 39\n",
      "Scraped 12 links from page 98\n",
      "Total Links: 1200\n"
     ]
    }
   ],
   "source": [
    "for page_number in range(1, jumlah_index + 1):\n",
    "    thread = threading.Thread(target=lambda p=page_number: links.extend(scrape_links(p)))\n",
    "    thread.start()\n",
    "    threads_link.append(thread)\n",
    "\n",
    "for thread in threads_link:\n",
    "    thread.join()\n",
    "print(\"Total Links:\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # title =[]\n",
    "        # author = []\n",
    "        # date = []\n",
    "        # content = []\n",
    "        # category =[]\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        # Judul Berita\n",
    "        title_elem = soup.find('h1')\n",
    "        if title_elem:\n",
    "            title_text = title_elem.text.strip()\n",
    "        else:\n",
    "            title_text = \"Title not found\"\n",
    "        # Author berita\n",
    "        author_elem = soup.find('div', {\"class\": \"author\"})\n",
    "        if author_elem:\n",
    "            author_text = author_elem.get_text()\n",
    "            author_text = author_text.split('-')[1].strip()\n",
    "            author_text = author_text.split(',')[0].strip()\n",
    "        else:\n",
    "            author_text = \"Author not found\"     \n",
    "        # tanggal berita\n",
    "        date_elem = soup.find('div', {\"class\": \"date\"})\n",
    "        if date_elem:\n",
    "            date_text = date_elem.text.strip()\n",
    "        else:\n",
    "            date_text = \"Date not found\"\n",
    "        #     # Category berita\n",
    "        category_elements = soup.find('ul', {\"class\": \"breadcrumb\"})\n",
    "        if category_elements:\n",
    "            category_text = category_elements.find_all('li')\n",
    "            category_text= category_text[2].get_text()\n",
    "        else:\n",
    "            category_text = \"Category not found\"\n",
    "        #     # Content Berita\n",
    "        body_elem = soup.find('div', {\"class\": \"detail_text\"})\n",
    "        \n",
    "        if body_elem:\n",
    "            content_elem = body_elem.find_all('p')\n",
    "            content_text = \"\"\n",
    "            for p in content_elem:\n",
    "                content_text += p.text.strip() + \"\\n\"\n",
    "            \n",
    "            if content_text.strip():\n",
    "                content_text=content_text\n",
    "            else:\n",
    "                content_text =\"Content not found\"\n",
    "        else:\n",
    "          content_text =\"Content not found\"\n",
    "\n",
    "        results.append({'title': title_text,\n",
    "                        'author' : author_text,\n",
    "                        'category':category_text,\n",
    "                        'date': date_text,\n",
    "                        'content' : content_text,\n",
    "                        'link' : url})\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    thread = threading.Thread(target=scrape_url, args=(url,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pemerintah: Pembangunan Harus Sejahterakan Rak...</td>\n",
       "      <td>CNBC Indonesia TV</td>\n",
       "      <td>Video News</td>\n",
       "      <td>25 September 2023 18:55</td>\n",
       "      <td>Jakarta, CNBC Indonesia- CNBC Indonesia mengge...</td>\n",
       "      <td>https://www.cnbcindonesia.com/news/20230925130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OJK Batasi Dividen Bank, Investor Bisa Untung ...</td>\n",
       "      <td>CNBC Indonesia TV</td>\n",
       "      <td>Video Market</td>\n",
       "      <td>25 September 2023 17:39</td>\n",
       "      <td>Jakarta, CNBC Indonesia- Otoritas Jasa Keuanga...</td>\n",
       "      <td>https://www.cnbcindonesia.com/market/202309251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RI Bakal Bentuk Badan Migas Baru, Begini Harus...</td>\n",
       "      <td>Verda Nano Setiawan</td>\n",
       "      <td>Berita</td>\n",
       "      <td>25 September 2023 17:40</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Indonesia sebentar l...</td>\n",
       "      <td>https://www.cnbcindonesia.com/news/20230925163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Proyek Rempang Eco City Jalan Terus, Tidak Ada...</td>\n",
       "      <td>Arrijal Rachman</td>\n",
       "      <td>Berita</td>\n",
       "      <td>25 September 2023 17:20</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Pemerintah melalui M...</td>\n",
       "      <td>https://www.cnbcindonesia.com/news/20230925163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPATK: 78% Penjudi Online Berpenghasilan di Ba...</td>\n",
       "      <td>CNBC Indonesia TV</td>\n",
       "      <td>Video News</td>\n",
       "      <td>25 September 2023 12:18</td>\n",
       "      <td>Jakarta, CNBC Indonesia- PPATK (Pusat Pelapora...</td>\n",
       "      <td>https://www.cnbcindonesia.com/news/20230925115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ekstremis Anti-Islam Robek Al-Qur'an di Depan ...</td>\n",
       "      <td>CNBC Indonesia TV</td>\n",
       "      <td>Video News</td>\n",
       "      <td>25 September 2023 17:17</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Kelompok anti-Islam ...</td>\n",
       "      <td>https://www.cnbcindonesia.com/news/20230925170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jokowi Bilang Media Sedang Tidak Baik-Baik Saja</td>\n",
       "      <td>Emir Yanwardhana</td>\n",
       "      <td>Berita Tech</td>\n",
       "      <td>25 September 2023 17:27</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Presiden Joko Widodo...</td>\n",
       "      <td>https://www.cnbcindonesia.com/tech/20230925171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harga Minyak Memanas Nyaris US$ 100, ESDM Keta...</td>\n",
       "      <td>Firda Dwi Muliawati</td>\n",
       "      <td>Berita</td>\n",
       "      <td>25 September 2023 19:50</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Kementerian Energi d...</td>\n",
       "      <td>https://www.cnbcindonesia.com/news/20230925184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Begini Penampakan Serpihan Alien, NASA Bawa ke...</td>\n",
       "      <td>AP Photo</td>\n",
       "      <td>Foto Tech</td>\n",
       "      <td>25 September 2023 18:50</td>\n",
       "      <td>Content not found</td>\n",
       "      <td>https://www.cnbcindonesia.com/tech/20230925081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RI Darurat Obesitas dan Diabetes, Kemenkes Lak...</td>\n",
       "      <td>Khoirul Anam</td>\n",
       "      <td>Berita</td>\n",
       "      <td>25 September 2023 17:25</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Angka obesitas di ta...</td>\n",
       "      <td>https://www.cnbcindonesia.com/news/20230925165...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               author  \\\n",
       "0  Pemerintah: Pembangunan Harus Sejahterakan Rak...    CNBC Indonesia TV   \n",
       "1  OJK Batasi Dividen Bank, Investor Bisa Untung ...    CNBC Indonesia TV   \n",
       "2  RI Bakal Bentuk Badan Migas Baru, Begini Harus...  Verda Nano Setiawan   \n",
       "3  Proyek Rempang Eco City Jalan Terus, Tidak Ada...      Arrijal Rachman   \n",
       "4  PPATK: 78% Penjudi Online Berpenghasilan di Ba...    CNBC Indonesia TV   \n",
       "5  Ekstremis Anti-Islam Robek Al-Qur'an di Depan ...    CNBC Indonesia TV   \n",
       "6    Jokowi Bilang Media Sedang Tidak Baik-Baik Saja     Emir Yanwardhana   \n",
       "7  Harga Minyak Memanas Nyaris US$ 100, ESDM Keta...  Firda Dwi Muliawati   \n",
       "8  Begini Penampakan Serpihan Alien, NASA Bawa ke...             AP Photo   \n",
       "9  RI Darurat Obesitas dan Diabetes, Kemenkes Lak...         Khoirul Anam   \n",
       "\n",
       "       category                     date  \\\n",
       "0    Video News  25 September 2023 18:55   \n",
       "1  Video Market  25 September 2023 17:39   \n",
       "2        Berita  25 September 2023 17:40   \n",
       "3        Berita  25 September 2023 17:20   \n",
       "4    Video News  25 September 2023 12:18   \n",
       "5    Video News  25 September 2023 17:17   \n",
       "6   Berita Tech  25 September 2023 17:27   \n",
       "7        Berita  25 September 2023 19:50   \n",
       "8     Foto Tech  25 September 2023 18:50   \n",
       "9        Berita  25 September 2023 17:25   \n",
       "\n",
       "                                             content  \\\n",
       "0  Jakarta, CNBC Indonesia- CNBC Indonesia mengge...   \n",
       "1  Jakarta, CNBC Indonesia- Otoritas Jasa Keuanga...   \n",
       "2  Jakarta, CNBC Indonesia - Indonesia sebentar l...   \n",
       "3  Jakarta, CNBC Indonesia - Pemerintah melalui M...   \n",
       "4  Jakarta, CNBC Indonesia- PPATK (Pusat Pelapora...   \n",
       "5  Jakarta, CNBC Indonesia - Kelompok anti-Islam ...   \n",
       "6  Jakarta, CNBC Indonesia - Presiden Joko Widodo...   \n",
       "7  Jakarta, CNBC Indonesia - Kementerian Energi d...   \n",
       "8                                  Content not found   \n",
       "9  Jakarta, CNBC Indonesia - Angka obesitas di ta...   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.cnbcindonesia.com/news/20230925130...  \n",
       "1  https://www.cnbcindonesia.com/market/202309251...  \n",
       "2  https://www.cnbcindonesia.com/news/20230925163...  \n",
       "3  https://www.cnbcindonesia.com/news/20230925163...  \n",
       "4  https://www.cnbcindonesia.com/news/20230925115...  \n",
       "5  https://www.cnbcindonesia.com/news/20230925170...  \n",
       "6  https://www.cnbcindonesia.com/tech/20230925171...  \n",
       "7  https://www.cnbcindonesia.com/news/20230925184...  \n",
       "8  https://www.cnbcindonesia.com/tech/20230925081...  \n",
       "9  https://www.cnbcindonesia.com/news/20230925165...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to ./excel/cnbc_2023-09-25_21-50-43.xlsx\n"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'./excel/cnbc_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempat Searching dan cek web\n",
    "# url = \"https://www.cnbcindonesia.com/news/20230924184706-4-475109/kota-hantu-china-bikin-pening-ada-72-juta-rumah-tak-laku\"  \n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# # author_elem = soup.find('ul', {\"class\": \"breadcrumb\"})\n",
    "# author_elem = soup.find('ul', {\"class\": \"breadcrumb\"})\n",
    "\n",
    "# author_text = author_elem.find_all('li')\n",
    "# # author_text = author_text.split('-')[1].strip()\n",
    "# # author_text = author_text.split(',')[0].strip()\n",
    "# print(author_text[2].get_text())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
