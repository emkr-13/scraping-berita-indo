{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_index = 50\n",
    "threads_link = []\n",
    "links = []\n",
    "results = []\n",
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(page_number):\n",
    "    url = f\"https://www.cnbcindonesia.com/indeks/{page_number}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all('article')\n",
    "    \n",
    "    page_links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    \n",
    "    print(f\"Scraped {len(page_links)} links from page {page_number}\")\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 10 links from page 5\n",
      "Scraped 10 links from page 16\n",
      "Scraped 10 links from page 28\n",
      "Scraped 10 links from page 6\n",
      "Scraped 10 links from page 8\n",
      "Scraped 10 links from page 3\n",
      "Scraped 10 links from page 25\n",
      "Scraped 10 links from page 37\n",
      "Scraped 10 links from page 27Scraped 10 links from page 29\n",
      "Scraped 10 links from page 7\n",
      "Scraped 10 links from page 30\n",
      "\n",
      "Scraped 10 links from page 45\n",
      "Scraped 10 links from page 35\n",
      "Scraped 10 links from page 17\n",
      "Scraped 10 links from page 10\n",
      "Scraped 10 links from page 24\n",
      "Scraped 10 links from page 4\n",
      "Scraped 10 links from page 22\n",
      "Scraped 10 links from page 11\n",
      "Scraped 10 links from page 1\n",
      "Scraped 10 links from page 39\n",
      "Scraped 10 links from page 21\n",
      "Scraped 10 links from page 38\n",
      "Scraped 10 links from page 34\n",
      "Scraped 10 links from page 12\n",
      "Scraped 10 links from page 41\n",
      "Scraped 10 links from page 19\n",
      "Scraped 10 links from page 42\n",
      "Scraped 10 links from page 49\n",
      "Scraped 10 links from page 32\n",
      "Scraped 10 links from page 14\n",
      "Scraped 10 links from page 13\n",
      "Scraped 10 links from page 43\n",
      "Scraped 10 links from page 40\n",
      "Scraped 10 links from page 48\n",
      "Scraped 10 links from page 26\n",
      "Scraped 10 links from page 15\n",
      "Scraped 10 links from page 33\n",
      "Scraped 10 links from page 23\n",
      "Scraped 10 links from page 44\n",
      "Scraped 10 links from page 50\n",
      "Scraped 10 links from page 47\n",
      "Scraped 10 links from page 46\n",
      "Scraped 10 links from page 2\n",
      "Scraped 10 links from page 20\n",
      "Scraped 10 links from page 31\n",
      "Scraped 10 links from page 36\n",
      "Scraped 10 links from page 18\n",
      "Scraped 10 links from page 9\n",
      "Total Links: 500\n"
     ]
    }
   ],
   "source": [
    "for page_number in range(1, jumlah_index + 1):\n",
    "    thread = threading.Thread(target=lambda p=page_number: links.extend(scrape_links(p)))\n",
    "    thread.start()\n",
    "    threads_link.append(thread)\n",
    "\n",
    "for thread in threads_link:\n",
    "    thread.join()\n",
    "print(\"Total Links:\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        # Judul Berita\n",
    "        title_elem = soup.find('h1')\n",
    "        if title_elem:\n",
    "            title_text = title_elem.text.strip()\n",
    "        else:\n",
    "            title_text = \"Title not found\"\n",
    "        # Author berita\n",
    "        author_elem = soup.find('div', {\"class\": \"author\"})\n",
    "        if author_elem:\n",
    "            author_text = author_elem.get_text()\n",
    "            author_text = author_text.split('-')[1].strip()\n",
    "            author_text = author_text.split(',')[0].strip()\n",
    "        else:\n",
    "            author_text = \"Author not found\"     \n",
    "        # tanggal berita\n",
    "        date_elem = soup.find('div', {\"class\": \"date\"})\n",
    "        if date_elem:\n",
    "            date_text = date_elem.text.strip()\n",
    "            datetime_object = datetime.strptime(date_text, '%d %B %Y %H:%M')\n",
    "            formatted_date = datetime_object.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            date_text = \"Date not found\"\n",
    "        #     # Category berita\n",
    "        category_elements = soup.find('ul', {\"class\": \"breadcrumb\"})\n",
    "        if category_elements:\n",
    "            category_text = category_elements.find_all('li')\n",
    "            category_text= category_text[2].get_text()\n",
    "        else:\n",
    "            category_text = \"Category not found\"\n",
    "        #     # Content Berita\n",
    "        body_elem = soup.find('div', {\"class\": \"detail_text\"})\n",
    "        \n",
    "        if body_elem:\n",
    "            content_elem = body_elem.find_all('p')\n",
    "            content_text = \"\"\n",
    "            for p in content_elem:\n",
    "                content_text += p.text.strip() + \"\\n\"\n",
    "            \n",
    "            if content_text.strip():\n",
    "                content_text=content_text\n",
    "            else:\n",
    "                content_text =\"Content not found\"\n",
    "        else:\n",
    "          content_text =\"Content not found\"\n",
    "          \n",
    "        nama_berita_match = re.search(r'https://www\\.(\\w+)\\.com/', url)\n",
    "        if nama_berita_match:\n",
    "            nama_berita = nama_berita_match.group(1)\n",
    "        else:\n",
    "             nama_berita = \"Nama_berita not found\"        \n",
    "\n",
    "        results.append({'title': title_text,\n",
    "                        'author' : author_text,\n",
    "                        'category':category_text,\n",
    "                        'date': formatted_date,\n",
    "                        'content' : content_text,\n",
    "                        'nama_berita' : nama_berita,\n",
    "                        'link' : url})\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-418 (scrape_url):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 404, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1058, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/ssl.py\", line 1108, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/ssl.py\", line 1379, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 799, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 404, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1058, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/urllib3/util/ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/ssl.py\", line 1108, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/ssl.py\", line 1379, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_21012/2998679178.py\", line 2, in scrape_url\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/krisna/anaconda3/lib/python3.11/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    }
   ],
   "source": [
    "for url in links:\n",
    "    thread = threading.Thread(target=scrape_url, args=(url,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>nama_berita</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UMKM EXPO(RT) BRILIANPRENEUR 2023 Hasilkan Kom...</td>\n",
       "      <td>Teti Purwanti</td>\n",
       "      <td>Berita Entrepreneur</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Jakarta, CNBC Indonesia - UMKM EXPO(RT) BRILIA...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/entrepreneur/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Korban Teriak! Tagihan Rp11 T, Wanaartha Cuma ...</td>\n",
       "      <td>Mentari Puspadini</td>\n",
       "      <td>Berita Market</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Nasabah PT Asuransi ...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/market/202312111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Video: Awal Pekan, IHSG &amp; Rupiah Ditutup Ambruk</td>\n",
       "      <td>CNBC Indonesia TV</td>\n",
       "      <td>Video Market</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Indeks Harga Saham G...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/market/202312111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 Rahasia Jepang Agar Bisnis Tak Bangkrut, Awe...</td>\n",
       "      <td>Muhammad Fakhriansyah</td>\n",
       "      <td>Berita Entrepreneur</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Dalam berbisnis sala...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/entrepreneur/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokopedia-TikTok Shop Bersatu, Ini Dampak ke E...</td>\n",
       "      <td>Novina Putri Bestari</td>\n",
       "      <td>Berita Tech</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Jakarta, CNBC Indonesia - GoTo melalui unit e-...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/tech/20231211154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ngeri! Israel, AS &amp; China Saingan Rilis Drone ...</td>\n",
       "      <td>Tim Redaksi</td>\n",
       "      <td>Berita Tech</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Di tengah perang Isr...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/tech/20231210115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Daftar iPhone Banting Harga di RI Desember 202...</td>\n",
       "      <td>Intan Rakhmayanti Dewi</td>\n",
       "      <td>Berita Tech</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Akhir tahun menjadi ...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/tech/20231211153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gak Cuma Cari Cuan, Ini Janji Anies Buat BUMN</td>\n",
       "      <td>Mentari Puspadini</td>\n",
       "      <td>Berita Market</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Calon Presiden Nomor...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/market/202312111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kinerja Saham Bank Big Caps</td>\n",
       "      <td></td>\n",
       "      <td>Audio Paham: Pantauan Saham</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Hai, Sobat Cuan..\\n\\nSaham perbankan masih men...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/cuap-cuap-cuan/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dua KEK Ini Terbukti Jadi Booster Ekonomi Indo...</td>\n",
       "      <td>Revo M</td>\n",
       "      <td>Berita Research</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Ada banyak strategi ...</td>\n",
       "      <td>cnbcindonesia</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2023121...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                  author  \\\n",
       "0  UMKM EXPO(RT) BRILIANPRENEUR 2023 Hasilkan Kom...           Teti Purwanti   \n",
       "1  Korban Teriak! Tagihan Rp11 T, Wanaartha Cuma ...       Mentari Puspadini   \n",
       "2    Video: Awal Pekan, IHSG & Rupiah Ditutup Ambruk       CNBC Indonesia TV   \n",
       "3  3 Rahasia Jepang Agar Bisnis Tak Bangkrut, Awe...   Muhammad Fakhriansyah   \n",
       "4  Tokopedia-TikTok Shop Bersatu, Ini Dampak ke E...    Novina Putri Bestari   \n",
       "5  Ngeri! Israel, AS & China Saingan Rilis Drone ...             Tim Redaksi   \n",
       "6  Daftar iPhone Banting Harga di RI Desember 202...  Intan Rakhmayanti Dewi   \n",
       "7      Gak Cuma Cari Cuan, Ini Janji Anies Buat BUMN       Mentari Puspadini   \n",
       "8                        Kinerja Saham Bank Big Caps                           \n",
       "9  Dua KEK Ini Terbukti Jadi Booster Ekonomi Indo...                  Revo M   \n",
       "\n",
       "                      category        date  \\\n",
       "0          Berita Entrepreneur  2023-12-11   \n",
       "1                Berita Market  2023-12-11   \n",
       "2                 Video Market  2023-12-11   \n",
       "3          Berita Entrepreneur  2023-12-11   \n",
       "4                  Berita Tech  2023-12-11   \n",
       "5                  Berita Tech  2023-12-10   \n",
       "6                  Berita Tech  2023-12-11   \n",
       "7                Berita Market  2023-12-11   \n",
       "8  Audio Paham: Pantauan Saham  2023-12-11   \n",
       "9              Berita Research  2023-12-10   \n",
       "\n",
       "                                             content    nama_berita  \\\n",
       "0  Jakarta, CNBC Indonesia - UMKM EXPO(RT) BRILIA...  cnbcindonesia   \n",
       "1  Jakarta, CNBC Indonesia - Nasabah PT Asuransi ...  cnbcindonesia   \n",
       "2  Jakarta, CNBC Indonesia - Indeks Harga Saham G...  cnbcindonesia   \n",
       "3  Jakarta, CNBC Indonesia - Dalam berbisnis sala...  cnbcindonesia   \n",
       "4  Jakarta, CNBC Indonesia - GoTo melalui unit e-...  cnbcindonesia   \n",
       "5  Jakarta, CNBC Indonesia - Di tengah perang Isr...  cnbcindonesia   \n",
       "6  Jakarta, CNBC Indonesia - Akhir tahun menjadi ...  cnbcindonesia   \n",
       "7  Jakarta, CNBC Indonesia - Calon Presiden Nomor...  cnbcindonesia   \n",
       "8  Hai, Sobat Cuan..\\n\\nSaham perbankan masih men...  cnbcindonesia   \n",
       "9  Jakarta, CNBC Indonesia - Ada banyak strategi ...  cnbcindonesia   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.cnbcindonesia.com/entrepreneur/202...  \n",
       "1  https://www.cnbcindonesia.com/market/202312111...  \n",
       "2  https://www.cnbcindonesia.com/market/202312111...  \n",
       "3  https://www.cnbcindonesia.com/entrepreneur/202...  \n",
       "4  https://www.cnbcindonesia.com/tech/20231211154...  \n",
       "5  https://www.cnbcindonesia.com/tech/20231210115...  \n",
       "6  https://www.cnbcindonesia.com/tech/20231211153...  \n",
       "7  https://www.cnbcindonesia.com/market/202312111...  \n",
       "8  https://www.cnbcindonesia.com/cuap-cuap-cuan/2...  \n",
       "9  https://www.cnbcindonesia.com/research/2023121...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to ../tempat_simpan_nasional/cnbc_data_baru_2023-12-11_20-31-01.xlsx\n"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'../tempat_simpan_nasional/cnbc_data_baru_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
