{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"keywords\": \"anies\",\n",
    "    \"since_time\": \"2023-09-01\",\n",
    "    \"until_time\": \"2023-11-10\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(date, keywords,page_number):\n",
    "    input_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    formatted_date_string = input_date.strftime(\"%Y/%m/%d\")\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = f\"https://www.cnbcindonesia.com/search?query={keywords}+&p={page_number}&kanal=&tipe=&date={formatted_date_string}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('article')\n",
    "        \n",
    "    links = []\n",
    "    for article in articles:\n",
    "            link = article.find('a')['href']\n",
    "            links.append(link)\n",
    "        \n",
    "    print(f\"Scraped {len(links)} links from page {page_number}\")\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_link_per_day(date, keywords,max_threads=5):\n",
    "    page_number = 1\n",
    "    page_links = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:\n",
    "        futures = []\n",
    "\n",
    "        while True:\n",
    "            future = executor.submit(scrape_links, date,keywords, page_number)\n",
    "            futures.append(future)\n",
    "            page_number += 1\n",
    "\n",
    "            # Break the loop if no more articles are found\n",
    "            if not future.result():\n",
    "                break\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            page_links.extend(future.result())\n",
    "\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 12 links from page 1\n",
      "Scraped 3 links from page 2\n",
      "Scraped 0 links from page 3\n"
     ]
    }
   ],
   "source": [
    "link=scrape_link_per_day(data[\"since_time\"],data[\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url,max_retries=2):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "            try:\n",
    "                headers = {\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "                }\n",
    "                response = requests.get(url, headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                    \n",
    "                    \n",
    "                    # Judul Berita\n",
    "                    title_elem = soup.find('h1')\n",
    "                    if title_elem:\n",
    "                        title_text = title_elem.text.strip()\n",
    "                    else:\n",
    "                        title_text = \"Title not found\" \n",
    "                    # tanggal berita\n",
    "                    date_elem = soup.find('div', {\"class\": \"date\"})\n",
    "                    if date_elem:\n",
    "                        date_text = date_elem.text.strip()\n",
    "                        datetime_object = datetime.strptime(date_text, '%d %B %Y %H:%M')\n",
    "                        formatted_date = datetime_object.strftime('%Y/%m/%d')\n",
    "                    else:\n",
    "                        date_text = \"Date not found\"\n",
    "                    #     # Content Berita\n",
    "                    body_elem = soup.find('div', {\"class\": \"read__content\"})\n",
    "                        \n",
    "                    body_elem = soup.find('div', {\"class\": \"detail_text\"})\n",
    "                    \n",
    "                    if body_elem:\n",
    "                        content_elem = body_elem.find_all('p')\n",
    "                        content_text = \"\"\n",
    "                        for p in content_elem:\n",
    "                            content_text += p.text.strip() + \"\\n\"\n",
    "                        \n",
    "                        if content_text.strip():\n",
    "                            content_text=content_text\n",
    "                            content_text = content_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "                            content_text = ' '.join(content_text.split())\n",
    "                            content_text= content_text.replace(\"ADVERTISEMENTSCROLL TO RESUME CONTENT\",\"\")\n",
    "                        else:\n",
    "                            content_text =\"Content not found\"\n",
    "                    else:\n",
    "                            content_text =\"Content not found\"\n",
    "\n",
    "                    return{\n",
    "                        'title': title_text,\n",
    "                        'date': formatted_date,\n",
    "                        'content':content_text,\n",
    "                        'link' : url}\n",
    "                elif response.status_code == 429:\n",
    "                    print(f\"Received a 429 error for {url}. Retrying in 5 seconds...\")\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve data from {url}: Status Code {response.status_code}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching URL '{url}': {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL '{url}': {e}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(f\"Retrying {url} (Attempt {retries}/{max_retries})\")\n",
    "                time.sleep(5)  # You can adjust the delay as needed\n",
    "    return None         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.cnbcindonesia.com/news/20231120085647-4-490296/jokowi-ri-akan-terus-mendukung-perjuangan-bangsa-palestina'\n",
    "cek=scrape_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Jokowi: RI akan Terus Mendukung Perjuangan Bangsa Palestina!', 'date': '2023/11/20', 'content': 'Jakarta, CNBC Indonesia - Presiden Republik Indonesia Joko Widodo menegaskan sikap Indonesia yang akan terus bersama mendukung perjuangan bangsa Palestina. Penegasan itu disampaikan Jokowi saat melepas bantuan kemanusiaan untuk Palestina tahap kedua di Pangkalan Tentara Nasional Indonesia Angkatan Udara Halim Perdanakusuma, Jakarta Timur, Senin (20/11/2023).Dalam sambutannya, mantan gubernur DKI Jakarta itu mengatakan, selain bantuan kemanusiaan, Indonesia juga akan terus memberikan dukungan politik bagi Palestina.Sebagai salah satu utusan khusus OKI, Menteri Luar Negeri RI Retno Marsudi juga sedang berada di beberapa negara untuk menggalang dukungan agar kekejaman di Gaza segera dihentikan, dilakukan sesegera mungkin gencatan senjata dan bantuan kemanusiaan bisa masuk dengan baik untuk membantu saudara-saudara kita di Gaza.\"Sekali lagi saya tegaskan, Indonesia akan terus bersama mendukung perjuangan bangsa Palestina,\" ujar Jokowi.Sebelumnya, bantuan tahap pertama dilepas Jokowi pada 4 November 2023. Menurut kepala negara, ada dua pesawat yang mengangkut bantuan seberat 21 ton berupa obat-obatan, perlengkapan rumah sakit, makanan, dan barang keperluan lainnya sesuai kebutuhan masyarakat di Gaza.Bantuan bersumber dari anggaran pemerintah sebesar Rp 31,9 miliar dan juga berasal dari perusahaan dan masyarakat antara lain dari PT Paragon Teknologi dan Inovasi, Indonesia Humanitarian Alliance, hingga Badan Amil Zakat Nasional.\"Sama seperti bantuan yang pertama, pesawat nanti akan menuju ke Mesir kemudian selanjutnya akan disalurkan ke Gaza,\" kata Jokowi.', 'link': 'https://www.cnbcindonesia.com/news/20231120085647-4-490296/jokowi-ri-akan-terus-mendukung-perjuangan-bangsa-palestina'}\n"
     ]
    }
   ],
   "source": [
    "print(cek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url in link:\n",
    "#     data_cnbc = scrape_url(url)\n",
    "#     print(data[\"keywords\"])\n",
    "#     keywords=data[\"keywords\"]\n",
    "#     if keywords.lower() in data_cnbc['title'].lower() or keywords.lower() in data_cnbc['content'].lower():\n",
    "#         print(\"Data contains keywords:\", data_cnbc)\n",
    "#     else:\n",
    "#         print(\"News does not contain the specified keywords and will not be inserted into the database. URL:\", data_cnbc['link'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
