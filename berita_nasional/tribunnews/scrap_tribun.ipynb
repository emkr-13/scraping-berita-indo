{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Link 20\n"
     ]
    }
   ],
   "source": [
    "links=[]\n",
    "# jumlah Page yang diambil \n",
    "jumlah_index = 1\n",
    "\n",
    "for index in range(jumlah_index):\n",
    "    url = f\"https://www.tribunnews.com/2023/09?page={index+1}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Chrome/117.0.0.0'})\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        articles = soup.find_all('li', {\"class\": \"ptb15\"})\n",
    "        for article in articles:\n",
    "            header = article.find('h3', {\"class\": \"fbo f16\"})\n",
    "            link = header.find('a')['href']\n",
    "            links.append(link)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while fetching data from {url}: {e}\")\n",
    "\n",
    "print(\"Jumlah Link\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "author = []\n",
    "editor =[]\n",
    "date = []\n",
    "content = []\n",
    "\n",
    "for link in links:\n",
    "    url = link \n",
    "    hdr = {'User-Agent': 'Chrome/117.0.0.0'}\n",
    "    req = Request(url,headers=hdr)\n",
    "    page = urlopen(req)  \n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    # Title Berita\n",
    "    title_elem = soup.find('h1', {\"id\": \"arttitle\"})\n",
    "    if title_elem:\n",
    "        \n",
    "        title_text = title_elem.text.strip()\n",
    "        # print(title_text)\n",
    "    else:\n",
    "        title_text = \"Title not found\"\n",
    "    title.append(title_text)\n",
    "    \n",
    "    # Author Berita\n",
    "    author_elem = soup.find('div', {\"id\": \"penulis\"})\n",
    "    if author_elem:\n",
    "        # print(author_elem)\n",
    "        penulis = author_elem.find('a')\n",
    "        author_text =penulis.text.strip()\n",
    "    else:\n",
    "        author_text = \"Author not found\"\n",
    "    author.append(author_text)\n",
    "    \n",
    "    # Editor Berita\n",
    "    editor_elem = soup.find('div', {\"id\": \"editor\"})\n",
    "    \n",
    "    if editor_elem:\n",
    "        editors = editor_elem.find('a')\n",
    "        editor_text = editors.text.strip()\n",
    "    else:\n",
    "        editor_text = \"editor not found\"\n",
    "    editor.append(editor_text)\n",
    "    \n",
    "    # date berita\n",
    "    date_elem = soup.find('time', {\"class\": \"grey\"})\n",
    "    if date_elem:\n",
    "        date_text = date_elem.text.strip()\n",
    "    else:\n",
    "        date_text = \"Date not found\"\n",
    "    date.append(date_text)\n",
    "    \n",
    "    \n",
    "    # content berita\n",
    "    body_elem = soup.find('div', {\"class\": \"side-article txt-article multi-fontsize\"})\n",
    "\n",
    "    if body_elem:\n",
    "        content_elem = body_elem.find_all('p')\n",
    "        content_text = \"\"\n",
    "        for p in content_elem:\n",
    "            content_text += p.text.strip() + \"\\n\"\n",
    "            \n",
    "        if content_text.strip():\n",
    "            content.append(content_text)\n",
    "        else:\n",
    "            content.append(\"Content not found\")\n",
    "    else:\n",
    "        content.append(\"Content not found\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>editor</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lestari Moerdijat Sebut Penerapan Nilai-Nilai ...</td>\n",
       "      <td>Fransisca Andeska</td>\n",
       "      <td>Content Writer</td>\n",
       "      <td>Senin, 25 September 2023 19:43 WIB</td>\n",
       "      <td>TRIBUNNEWS.COM - Wakil Ketua MPR RI Lestari Mo...</td>\n",
       "      <td>https://www.tribunnews.com/nasional/2023/09/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDIP: Pilpres 2024 Bisa Tiga atau Dua Poros, A...</td>\n",
       "      <td>Rizki Sandi Saputra</td>\n",
       "      <td>Malvyandie Haryadi</td>\n",
       "      <td>Senin, 25 September 2023 19:42 WIB</td>\n",
       "      <td>Laporan Reporter Tribunnews.com, Rizki Sandi S...</td>\n",
       "      <td>https://www.tribunnews.com/mata-lokal-memilih/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ditinggal Sang Predator ke Timnas, Persis Solo...</td>\n",
       "      <td>Alfarizy Ajie Fadhillah</td>\n",
       "      <td>Muhammad Barir</td>\n",
       "      <td>Senin, 25 September 2023 19:41 WIB</td>\n",
       "      <td>Laporan Wartawan Tribunnews.com, Alfarizy AF\\n...</td>\n",
       "      <td>https://www.tribunnews.com/superskor/2023/09/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ketua MPR RI Bamsoet Dukung Langkah KADIN dala...</td>\n",
       "      <td>Fransisca Andeska</td>\n",
       "      <td>Content Writer</td>\n",
       "      <td>Senin, 25 September 2023 19:40 WIB</td>\n",
       "      <td>TRIBUNNEWS.COM - Ketua MPR RI sekaligus Wakil ...</td>\n",
       "      <td>https://www.tribunnews.com/nasional/2023/09/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binaragawan Oscar Tamio Kembali Bertekad Harum...</td>\n",
       "      <td>Abdul Majid</td>\n",
       "      <td>Muhammad Barir</td>\n",
       "      <td>Senin, 25 September 2023 19:37 WIB</td>\n",
       "      <td>TRIBUNNEWS.COM, JAKARTA – Binaragawan Oscar Ta...</td>\n",
       "      <td>https://www.tribunnews.com/sport/2023/09/25/bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                   author  \\\n",
       "0  Lestari Moerdijat Sebut Penerapan Nilai-Nilai ...        Fransisca Andeska   \n",
       "1  PDIP: Pilpres 2024 Bisa Tiga atau Dua Poros, A...      Rizki Sandi Saputra   \n",
       "2  Ditinggal Sang Predator ke Timnas, Persis Solo...  Alfarizy Ajie Fadhillah   \n",
       "3  Ketua MPR RI Bamsoet Dukung Langkah KADIN dala...        Fransisca Andeska   \n",
       "4  Binaragawan Oscar Tamio Kembali Bertekad Harum...              Abdul Majid   \n",
       "\n",
       "               editor                                date  \\\n",
       "0      Content Writer  Senin, 25 September 2023 19:43 WIB   \n",
       "1  Malvyandie Haryadi  Senin, 25 September 2023 19:42 WIB   \n",
       "2      Muhammad Barir  Senin, 25 September 2023 19:41 WIB   \n",
       "3      Content Writer  Senin, 25 September 2023 19:40 WIB   \n",
       "4      Muhammad Barir  Senin, 25 September 2023 19:37 WIB   \n",
       "\n",
       "                                             content  \\\n",
       "0  TRIBUNNEWS.COM - Wakil Ketua MPR RI Lestari Mo...   \n",
       "1  Laporan Reporter Tribunnews.com, Rizki Sandi S...   \n",
       "2  Laporan Wartawan Tribunnews.com, Alfarizy AF\\n...   \n",
       "3  TRIBUNNEWS.COM - Ketua MPR RI sekaligus Wakil ...   \n",
       "4  TRIBUNNEWS.COM, JAKARTA – Binaragawan Oscar Ta...   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.tribunnews.com/nasional/2023/09/25...  \n",
       "1  https://www.tribunnews.com/mata-lokal-memilih/...  \n",
       "2  https://www.tribunnews.com/superskor/2023/09/2...  \n",
       "3  https://www.tribunnews.com/nasional/2023/09/25...  \n",
       "4  https://www.tribunnews.com/sport/2023/09/25/bi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "        'title': title,\n",
    "        'author' : author,\n",
    "        'editor' : editor,\n",
    "        'date': date,\n",
    "        'content' : content,\n",
    "        'link' : links\n",
    "        }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempat save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to ./excel/tribunews_2023-09-25_19-43-32.xlsx\n"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'./excel/tribunews_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Buat Latihan dan pengecek\n",
    "# links=[]\n",
    "# # jumlah Page yang diambil \n",
    "# jumlah_index = 2\n",
    "# for index in range(jumlah_index):\n",
    "#     url = f\"https://www.tribunnews.com/2023/09?page={index+1}\"\n",
    "#     # print(url)  \n",
    "#     hdr = {'User-Agent': 'Chrome/117.0.0.0'}\n",
    "#     req = Request(url,headers=hdr)\n",
    "#     page = urlopen(req)\n",
    "#     soup = BeautifulSoup(page)\n",
    "#     articles = soup.find_all('li', {\"class\": \"ptb15\"})\n",
    "#     # print(articles)\n",
    "#     for article in articles:\n",
    "#             header = article.find('h3', {\"class\": \"fbo f16\"})\n",
    "#             link = header.find('a')['href']\n",
    "#             links.append(link)\n",
    "    \n",
    "# print(len(links))\n",
    "# print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.tribunnews.com/seleb/2023/09/25/lama-tak-muncul-di-layar-kaca-andi-arsyil-mengaku-tak-takut-dilupakan-oleh-fans-gak-butuh-validasi\"\n",
    "    # print(url)  \n",
    "hdr = {'User-Agent': 'Chrome/117.0.0.0'}\n",
    "req = Request(url,headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "# title berita\n",
    "# articles = soup.find('h1', {\"id\": \"arttitle\"})\n",
    "# print(articles.text.strip())\n",
    "\n",
    "# authors berita\n",
    "# articles = soup.find('div', {\"id\": \"penulis\"})\n",
    "# penulis = articles.find('a')\n",
    "# print(penulis.text.strip())\n",
    "\n",
    "# editor berita\n",
    "# articles = soup.find('div', {\"id\": \"editor\"})\n",
    "# penulis = articles.find('a')\n",
    "# print(penulis.text.strip())\n",
    "\n",
    "# isi berita \n",
    "# articles = soup.find('div', {\"class\": \"side-article txt-article multi-fontsize\"})\n",
    "# body_elem = soup.find('div', {\"class\": \"side-article txt-article multi-fontsize\"})\n",
    "\n",
    "# if body_elem:\n",
    "#     content_elem = body_elem.find_all('p')\n",
    "#     content_text = \"\"\n",
    "#     for p in content_elem:\n",
    "#         content_text += p.text.strip() + \"\\n\"\n",
    "        \n",
    "#     if content_text.strip():\n",
    "#         content.append(content_text)\n",
    "#     else:\n",
    "#         content.append(\"Content not found\")\n",
    "# else:\n",
    "#     content.append(\"Content not found\")\n",
    "\n",
    "# print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
