{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from dateutil import parser,tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     \"keywords\": \"anies\",\n",
    "#     \"since_time\": \"2023-09-01\",\n",
    "#     \"until_time\": \"2023-11-10\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input_date_str = datetime.strftime(data['since_time'], \"%Y-%m-%d\")\n",
    "# input_date_str=data['since_time']\n",
    "# print(input_date_str)\n",
    "# # headers = {\n",
    "# #         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "# #     }\n",
    "# # url = f\"https://index.okezone.com/bydate/channel/2023/09/01/1\"\n",
    "# # response = requests.get(url, headers=headers)\n",
    "# # soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# # response = requests.get(url, headers=headers)\n",
    "# # soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# # articles = soup.find_all('h4', {\"class\": \"f17\"})\n",
    "# # for article in articles:\n",
    "# #     link = article.find('a')['href']\n",
    "# #     print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = {\n",
    "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "#     }\n",
    "# url = f\"https://index.okezone.com/bydate/channel/2023/09/01/1\"\n",
    "# response = requests.get(url, headers=headers)\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# # print(soup)\n",
    "# cek = soup.find('div', {\"class\": \"time r1 fl bg1 b1\"})\n",
    "# links=cek.find_all('a')\n",
    "# all_link=[]\n",
    "# for link in links:\n",
    "#         if link and 'href' in link.attrs:\n",
    "#             link_href = link['href']\n",
    "#             all_link.append(link_href)\n",
    "# link=all_link[-1]\n",
    "# # print(link)\n",
    "# parsed_url = urlparse(link)\n",
    "# # print(parsed_url)\n",
    "# number = parsed_url.path.split(\"/\")[-2]\n",
    "# # print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://nasional.okezone.com/read/2023/12/01/337/2931151/stafsus-jokowi-ajak-pemuda-suarakan-hentikan-peperangan', 'https://sports.okezone.com/read/2023/12/01/43/2931147/seru-enam-tim-memperebutkan-gelar-juara-liga-1-esports-nasional-2023', 'https://news.okezone.com/read/2023/12/01/340/2931145/tingkatkan-kesadaran-publik-tentang-isu-air-kementerian-pupr-gelar-pameran-water-art-installation', 'https://index.okezone.com/read/2023/12/01/612/2931018/ini-arti-mimpi-gigi-copot-takut-di-bawah-alam-sadar-hingga-depresi', 'https://news.okezone.com/read/2023/12/01/340/2931134/hadiri-munas-pramuka-di-aceh-atikoh-ganjar-pranowo-dapat-sambutan-hangat', 'https://celebrity.okezone.com/read/2023/12/01/205/2931144/summerlane-sukses-meriahkan-music-zone-by-okezone-radio', 'https://economy.okezone.com/read/2023/12/01/11/2931143/kontribusi-ekonomi-berkelanjutan-pegadaian-raih-dua-penghargaan-top-bumn-awards-2023', 'https://health.okezone.com/read/2023/12/01/483/2931139/6-bahaya-kebanyakan-makan-protein-apa-saja', 'https://index.okezone.com/read/2023/12/01/612/2931137/datang-ke-munas-pramuka-xi-di-aceh-siti-atikoh-dapat-sambutan-hangat', 'https://index.okezone.com/read/2023/12/01/612/2930913/20-panggilan-sayang-dalam-bahasa-jepang-bisa-kamu-ungkapkan-pada-pasangan', 'https://news.okezone.com/read/2023/12/01/340/2931135/bersama-sandiaga-uno-alam-ganjar-bicara-kepemimpinan-dan-bisnis-bersama-pemuda-makassar', 'https://celebrity.okezone.com/read/2023/12/01/205/2931085/brandon-julio-sejukkan-hati-di-music-zone-by-okezone-radio-bikin-penonton-ogah-pulang', 'https://news.okezone.com/read/2023/12/01/340/2931132/jelang-munas-pramuka-atikoh-ganjar-kulineran-dan-seruput-kopi-khas-serambi-mekkah', 'https://health.okezone.com/read/2023/12/01/481/2930735/apakah-ada-buah-yang-tidak-dianjurkan-untuk-pasien-tuberkulosis-ini-kata-pakar', 'https://news.okezone.com/read/2023/12/01/609/2931130/di-sandination-makassar-alam-ganjar-sebut-pemimpin-perlu-jadi-good-listener']\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "url = f\"https://index.okezone.com/bydate/index/2023/12/01/0/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "body= soup.find('div',{\"class\":\"news-content\"})\n",
    "\n",
    "articles = body.find_all('div', {\"class\": \"content-hardnews pad-index\"})\n",
    "    \n",
    "links = []\n",
    "for article in articles:\n",
    "    link = article.find('a')['href']\n",
    "    links.append(link)\n",
    "    \n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(date, page_number):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = f\"https://index.okezone.com/bydate/index/{date}/{page_number}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    body= soup.find('div',{\"class\":\"news-content\"})\n",
    "\n",
    "    articles = body.find_all('div', {\"class\": \"content-hardnews pad-index\"})\n",
    "    \n",
    "    links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        links.append(link)\n",
    "        \n",
    "    print(f\"Scraped {len(links)} links from page {page_number} url {url}\")\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_link_per_day(date, max_threads=5):\n",
    "    page_number = 0\n",
    "    page_links = []\n",
    "    # Adjust the date format here\n",
    "    current_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    formatted_date = current_date.strftime(\"%Y/%m/%d\")\n",
    "    # print(formatted_date)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:\n",
    "        futures = []\n",
    "\n",
    "        while True:\n",
    "            future = executor.submit(scrape_links, formatted_date, page_number)\n",
    "            futures.append(future)\n",
    "            page_number += 15\n",
    "\n",
    "            # Break the loop if no more articles are found\n",
    "            if not future.result():\n",
    "                break\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            page_links.extend(future.result())\n",
    "\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 15 links from page 0 url https://index.okezone.com/bydate/index/2023/11/02/0\n",
      "Scraped 15 links from page 15 url https://index.okezone.com/bydate/index/2023/11/02/15\n",
      "Scraped 15 links from page 30 url https://index.okezone.com/bydate/index/2023/11/02/30\n",
      "Scraped 15 links from page 45 url https://index.okezone.com/bydate/index/2023/11/02/45\n",
      "Scraped 15 links from page 60 url https://index.okezone.com/bydate/index/2023/11/02/60\n",
      "Scraped 15 links from page 75 url https://index.okezone.com/bydate/index/2023/11/02/75\n",
      "Scraped 15 links from page 90 url https://index.okezone.com/bydate/index/2023/11/02/90\n",
      "Scraped 15 links from page 105 url https://index.okezone.com/bydate/index/2023/11/02/105\n",
      "Scraped 15 links from page 120 url https://index.okezone.com/bydate/index/2023/11/02/120\n",
      "Scraped 15 links from page 135 url https://index.okezone.com/bydate/index/2023/11/02/135\n",
      "Scraped 15 links from page 150 url https://index.okezone.com/bydate/index/2023/11/02/150\n",
      "Scraped 15 links from page 165 url https://index.okezone.com/bydate/index/2023/11/02/165\n",
      "Scraped 15 links from page 180 url https://index.okezone.com/bydate/index/2023/11/02/180\n",
      "Scraped 15 links from page 195 url https://index.okezone.com/bydate/index/2023/11/02/195\n",
      "Scraped 15 links from page 210 url https://index.okezone.com/bydate/index/2023/11/02/210\n",
      "Scraped 15 links from page 225 url https://index.okezone.com/bydate/index/2023/11/02/225\n",
      "Scraped 15 links from page 240 url https://index.okezone.com/bydate/index/2023/11/02/240\n",
      "Scraped 15 links from page 255 url https://index.okezone.com/bydate/index/2023/11/02/255\n",
      "Scraped 15 links from page 270 url https://index.okezone.com/bydate/index/2023/11/02/270\n",
      "Scraped 15 links from page 285 url https://index.okezone.com/bydate/index/2023/11/02/285\n",
      "Scraped 15 links from page 300 url https://index.okezone.com/bydate/index/2023/11/02/300\n",
      "Scraped 15 links from page 315 url https://index.okezone.com/bydate/index/2023/11/02/315\n",
      "Scraped 15 links from page 330 url https://index.okezone.com/bydate/index/2023/11/02/330\n",
      "Scraped 15 links from page 345 url https://index.okezone.com/bydate/index/2023/11/02/345\n",
      "Scraped 15 links from page 360 url https://index.okezone.com/bydate/index/2023/11/02/360\n",
      "Scraped 15 links from page 375 url https://index.okezone.com/bydate/index/2023/11/02/375\n",
      "Scraped 15 links from page 390 url https://index.okezone.com/bydate/index/2023/11/02/390\n",
      "Scraped 15 links from page 405 url https://index.okezone.com/bydate/index/2023/11/02/405\n",
      "Scraped 15 links from page 420 url https://index.okezone.com/bydate/index/2023/11/02/420\n",
      "Scraped 15 links from page 435 url https://index.okezone.com/bydate/index/2023/11/02/435\n",
      "Scraped 15 links from page 450 url https://index.okezone.com/bydate/index/2023/11/02/450\n",
      "Scraped 15 links from page 465 url https://index.okezone.com/bydate/index/2023/11/02/465\n",
      "Scraped 15 links from page 480 url https://index.okezone.com/bydate/index/2023/11/02/480\n",
      "Scraped 15 links from page 495 url https://index.okezone.com/bydate/index/2023/11/02/495\n",
      "Scraped 15 links from page 510 url https://index.okezone.com/bydate/index/2023/11/02/510\n",
      "Scraped 15 links from page 525 url https://index.okezone.com/bydate/index/2023/11/02/525\n",
      "Scraped 15 links from page 540 url https://index.okezone.com/bydate/index/2023/11/02/540\n",
      "Scraped 15 links from page 555 url https://index.okezone.com/bydate/index/2023/11/02/555\n",
      "Scraped 15 links from page 570 url https://index.okezone.com/bydate/index/2023/11/02/570\n",
      "Scraped 15 links from page 585 url https://index.okezone.com/bydate/index/2023/11/02/585\n",
      "Scraped 15 links from page 600 url https://index.okezone.com/bydate/index/2023/11/02/600\n",
      "Scraped 15 links from page 615 url https://index.okezone.com/bydate/index/2023/11/02/615\n",
      "Scraped 15 links from page 630 url https://index.okezone.com/bydate/index/2023/11/02/630\n",
      "Scraped 15 links from page 645 url https://index.okezone.com/bydate/index/2023/11/02/645\n",
      "Scraped 15 links from page 660 url https://index.okezone.com/bydate/index/2023/11/02/660\n",
      "Scraped 15 links from page 675 url https://index.okezone.com/bydate/index/2023/11/02/675\n",
      "Scraped 14 links from page 690 url https://index.okezone.com/bydate/index/2023/11/02/690\n",
      "Scraped 0 links from page 705 url https://index.okezone.com/bydate/index/2023/11/02/705\n"
     ]
    }
   ],
   "source": [
    "link=scrape_link_per_day('2023-11-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n"
     ]
    }
   ],
   "source": [
    "print(len(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url, max_retries=2):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Judul Berita\n",
    "                title_elem = soup.find('div', {\"class\": \"title\"})\n",
    "                if title_elem:\n",
    "                    title_text = title_elem.text.strip()\n",
    "                else:\n",
    "                    title_text = \"Title not found\"\n",
    "\n",
    "                # Tanggal berita\n",
    "                date_elem = soup.find('div', {\"class\": \"reporter\"})\n",
    "                if date_elem:\n",
    "                    date_text = date_elem.text.strip()\n",
    "                    # Define a custom timezone information for WIB\n",
    "                    def wib_tz(offset):\n",
    "                        return tz.tzoffset('WIB', offset)\n",
    "\n",
    "                    # Parse the date string with the custom timezone information\n",
    "                    date_object = parser.parse(date_text, tzinfos={'WIB': 7*60}, fuzzy=True)\n",
    "\n",
    "                    # Format the datetime object to the desired format\n",
    "                    formatted_date = date_object.strftime('%Y-%m-%d')\n",
    "\n",
    "                else:\n",
    "                    date_text = \"Date not found\"\n",
    "\n",
    "                # Content Berita\n",
    "                body_elem = soup.find('div', {\"class\": \"read\"})\n",
    "\n",
    "                if body_elem:\n",
    "                    content_text = body_elem.text\n",
    "                    content_text = content_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "                    content_text = ' '.join(content_text.split())\n",
    "                else:\n",
    "                    content_text = \"Content not found\"\n",
    "\n",
    "                return {\n",
    "                    'title': title_text,\n",
    "                    'date': formatted_date,\n",
    "                    'content': content_text,\n",
    "                    'link': url\n",
    "                }\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Received a 429 error for {url}. Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data from {url}: Status Code {response.status_code}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching URL '{url}': {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing URL '{url}': {e}\")\n",
    "        retries += 1\n",
    "        if retries < max_retries:\n",
    "            print(f\"Retrying {url} (Attempt {retries}/{max_retries})\")\n",
    "            time.sleep(5)  # You can adjust the delay as needed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cek = scrape_url('https://nasional.okezone.com/read/2023/12/01/337/2931151/stafsus-jokowi-ajak-pemuda-suarakan-hentikan-peperangan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Stafsus Jokowi Ajak Pemuda Suarakan Hentikan Peperangan',\n",
       " 'date': '2023-01-02',\n",
       " 'content': 'DUBAI - Staf Khusus Presiden Jokowi, Diaz Hendropriyono tegaskan bahwa Indonesia siap berperan meminimalkan dampak perubahan iklim melalui inovasi-inovasi para ecopreneurs yang tersebar di seluruh Indonesia. Menjadi bagian dari gelaran tahunan PBB yang memobilisasi gerakan aksi global untuk membatasi kenaikan suhu dunia akibat pemanasan global atau Conference of the Parties (COP) ke-28, Diaz menyampaikan Indonesia mampu memberi harapan bagi dunia karena memiliki banyak ecopreneur yang menciptakan inovasi-inovasi produk ramah lingkungan dengan tujuan mengurangi emisi gas rumah kaca.BACA JUGA:Seru, Enam Tim Memperebutkan Gelar Juara Liga 1 Esports Nasional 2023Konferensi Tingkat Tinggi yang dilaksanakan di Dubai, Uni Emirat Arab (UEA) mulai dari 30 November ini dihadiri oleh puluhan ribu delegasi dari 199 Pihak Konvensi UN Framework Convention on Climate Change (UNFCCC).Dalam salah satu sesi, yaitu “Youth and Renewable Energy: Our Hope, Our Action” Diaz yang menjadi pembicara kunci kembali menegaskan bahwa ancaman pemanasan global sangat mengkhawatirkan dan sudah ada di depan mata. Bahkan pemanasan global dan perubahan iklim dapat memakan korban jiwa lebih banyak dari peperangan, serangan terorisme, dan bencana alam.BACA JUGA:Tingkatkan Kesadaran Publik tentang Isu Air, Kementerian PUPR Gelar Pameran Water Art Installation“Selain membunuh jutaan orang, peperangan menyumbangkan 5,5% emisi gas rumah kaca setiap tahunnya. Oleh karena itu kita, terutama anak muda, harus menyuarakan kepada pemerintahan dunia untuk menghentikan konflik dan peperangan karena dapat memperparah pemanasan global dan membunuh lebih banyak orang,” ujar Diaz, Jumat (1/12/2023).Follow Berita Okezone di Google NewsDapatkan berita up to date dengan semua berita terkini dari Okezone hanya dengan satu akun di ORION, daftar sekarang dengan klik disini dan nantikan kejutan menarik lainnya Aksi-aksi inovatif dari pemuda di Indonesia di sektor konstruksi, pakaian, pangan, hingga pengolahan sampah ini fokus untuk mengembangkan ekonomi berkelanjutan yang maju secara bisnis tetapi tidak mengorbankan lingkungan melainkan menjunjung ekonomi sirkular.Salah satu fokus COP28 kali ini menggarisbawahi pentingnya pendanaan untuk adaptasi dan investasi dalam ketahanan iklim. Oleh karena itu, dalam kesempatan ini Diaz juga menyampaikan bahwasannya inovasi-inovasi yang saat ini tersedia, terutama oleh para ecopreneurs di Indonesia berpeluang besar untuk membantu menyelamatkan potensi emisi GRK yang terlepas ke atmosfer. Namun, hal tersebut pasti membutuhkan dukungan investasi.Sesi tersebut turut dihadiri beberapa tokoh diantaranya, Wakil Menteri Lingkungan HIdup dan Kehutanan Alue Dohong, Pengusaha Boy Thohir, dan Anggota DPR 2014-2019 Akbar Faizal. Sebelumnya12Selanjutnya #Diaz Hendropriyono #Stafsus Jokowi Diaz Hendropriyono #Perang #Perubahan Iklim',\n",
       " 'link': 'https://nasional.okezone.com/read/2023/12/01/337/2931151/stafsus-jokowi-ajak-pemuda-suarakan-hentikan-peperangan'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
