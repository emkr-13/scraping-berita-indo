{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Detik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengecek Link status Ok\n",
    "url = \"https://news.detik.com/index\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_index = 1\n",
    "threads_link = []\n",
    "links = []\n",
    "results = []\n",
    "keywords = 'ganjar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(page_number,keywords):\n",
    "    url = f\"https://www.detik.com/search/searchall?query={keywords}&sortby=time&page={page_number}\"\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all('article')\n",
    "    \n",
    "    page_links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        page_links.append(link)\n",
    "    \n",
    "    print(f\"Scraped {len(page_links)} links from page {page_number}\")\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.detik.com/search/searchall?query=ganjar&sortby=time&page=1\n",
      "Scraped 9 links from page 1\n",
      "Total Links: 9\n"
     ]
    }
   ],
   "source": [
    "for page_number in range(1, jumlah_index + 1):\n",
    "    thread = threading.Thread(target=lambda p=page_number: links.extend(scrape_links(p,keywords)))\n",
    "    thread.start()\n",
    "    threads_link.append(thread)\n",
    "\n",
    "for thread in threads_link:\n",
    "    thread.join()\n",
    "print(\"Total Links:\", len(links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url,keywords):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # title =[]\n",
    "        # author = []\n",
    "        # date = []\n",
    "        # content = []\n",
    "        # category =[]\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        # Judul Berita\n",
    "        title_elem = soup.find('h1', {\"class\": \"detail__title\"})\n",
    "        if title_elem:\n",
    "            title_text = title_elem.text.strip()\n",
    "        else:\n",
    "            title_text = \"Title not found\"\n",
    "        # Author berita\n",
    "        author_elem = soup.find('div', {\"class\": \"detail__author\"})\n",
    "        if author_elem:\n",
    "            author_text = author_elem.get_text()\n",
    "            author_text = author_text.split('-')[0].strip()\n",
    "        else:\n",
    "            author_text = \"Author not found\"     \n",
    "        # tanggal berita\n",
    "        date_elem = soup.find('div', {\"class\": \"detail__date\"})\n",
    "        if date_elem:\n",
    "            date_text = date_elem.text.strip()\n",
    "        else:\n",
    "            date_text = \"Date not found\"\n",
    "        #     # Category berita\n",
    "        category_elements = soup.find('div',{\"class\": \"page__breadcrumb\"})\n",
    "        if category_elements:\n",
    "            category_text = category_elements.find('a',{\"dtr-sec\": \"breadcrumbkanal\"})\n",
    "            category_text= category_text.text.strip()\n",
    "        else:\n",
    "            category_text = \"Category not found\"\n",
    "        #     # Content Berita\n",
    "        body_elem = soup.find('div', {\"class\": \"detail__body\"})\n",
    "        \n",
    "        if body_elem:\n",
    "            content_elem = body_elem.find_all('p')\n",
    "            content_text = \"\"\n",
    "            for p in content_elem:\n",
    "                content_text += p.text.strip() + \"\\n\"\n",
    "            \n",
    "            if content_text.strip():\n",
    "                content_text=content_text\n",
    "            else:\n",
    "                content_text =\"Content not found\"\n",
    "        else:\n",
    "          content_text =\"Content not found\"\n",
    "\n",
    "        results.append({'title': title_text,\n",
    "                        'keywords':keywords,\n",
    "                        'author' : author_text,\n",
    "                        'category':category_text,\n",
    "                        'date': date_text,\n",
    "                        'content' : content_text,\n",
    "                        'link' : url})\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for url in links:\n",
    "    thread = threading.Thread(target=scrape_url, args=(url,keywords))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jadi Ketua TPN Ganjar, Arsjad Rasjid Cuti dari...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Marlinda Oktavia Erwanti</td>\n",
       "      <td>Pemilu</td>\n",
       "      <td>Selasa, 26 Sep 2023 09:25 WIB</td>\n",
       "      <td>Ketua Tim Pemenangan Nasional (TPN) bakal calo...</td>\n",
       "      <td>https://news.detik.com/pemilu/d-6950733/jadi-k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jokowi: Beda Pilihan itu Wajar, Mau Pilih Prab...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Indra Komara</td>\n",
       "      <td>Pemilu</td>\n",
       "      <td>Selasa, 26 Sep 2023 17:24 WIB</td>\n",
       "      <td>Presiden Joko Widodo (Jokowi) mengingatkan kad...</td>\n",
       "      <td>https://news.detik.com/pemilu/d-6951804/jokowi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Projo Bakal Dukung Capres yang Depannya P</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Tara Wahyu NV</td>\n",
       "      <td>Pemilu</td>\n",
       "      <td>Selasa, 26 Sep 2023 15:29 WIB</td>\n",
       "      <td>Relawan pendukung Presiden Joko Widodo (Jokowi...</td>\n",
       "      <td>https://news.detik.com/pemilu/d-6951509/projo-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Menerka Sosok Cawapres Ganjar Jika Megawati Ta...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Kadek Melda Luxiana</td>\n",
       "      <td>Pemilu</td>\n",
       "      <td>Selasa, 26 Sep 2023 08:45 WIB</td>\n",
       "      <td>PPP meminta Ketum PDIP, Megawati Soekaroputri ...</td>\n",
       "      <td>https://news.detik.com/pemilu/d-6950710/menerk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soal Hubungan Megawati dan Jokowi Usai Kaesang...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Tim detikcom</td>\n",
       "      <td>Pemilu</td>\n",
       "      <td>Selasa, 26 Sep 2023 09:03 WIB</td>\n",
       "      <td>Putra Presiden Joko Widodo (Jokowi), Kaesang P...</td>\n",
       "      <td>https://news.detik.com/pemilu/d-6950719/soal-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BEM FISIP Se-Surabaya Tantang 3 Capres Adu Gag...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Esti Widiyana</td>\n",
       "      <td>Berita</td>\n",
       "      <td>Selasa, 26 Sep 2023 15:46 WIB</td>\n",
       "      <td>Badan Eksekutif Mahasiswa Fakultas Ilmu Sosial...</td>\n",
       "      <td>https://www.detik.com/jatim/berita/d-6951552/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ketum Projo Bocorkan Nama Capres yang Akan Did...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Tara Wahyu NV</td>\n",
       "      <td>Berita</td>\n",
       "      <td>Selasa, 26 Sep 2023 14:51 WIB</td>\n",
       "      <td>Projo, organisasi pendukung Presiden Joko Wido...</td>\n",
       "      <td>https://www.detik.com/jateng/berita/d-6951412/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harapan Besar Pecinta Budaya Populer Indonesia...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Atmi Ahsani Yusron</td>\n",
       "      <td>Berita Kpop</td>\n",
       "      <td>Selasa, 26 Sep 2023 14:24 WIB</td>\n",
       "      <td>Muda-mudi Indonesia sedang bergelora dua tahun...</td>\n",
       "      <td>https://hot.detik.com/berita-kpop/d-6951328/ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jadi Ketua TPN Ganjar Pranowo, Arsjad Rasjid C...</td>\n",
       "      <td>ganjar</td>\n",
       "      <td>Anisa Indraini</td>\n",
       "      <td>Berita Ekonomi Bisnis</td>\n",
       "      <td>Selasa, 26 Sep 2023 09:10 WIB</td>\n",
       "      <td>Ketua Umum Kamar Dagang dan Industri (KADIN) I...</td>\n",
       "      <td>https://finance.detik.com/berita-ekonomi-bisni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title keywords  \\\n",
       "0  Jadi Ketua TPN Ganjar, Arsjad Rasjid Cuti dari...   ganjar   \n",
       "1  Jokowi: Beda Pilihan itu Wajar, Mau Pilih Prab...   ganjar   \n",
       "2          Projo Bakal Dukung Capres yang Depannya P   ganjar   \n",
       "3  Menerka Sosok Cawapres Ganjar Jika Megawati Ta...   ganjar   \n",
       "4  Soal Hubungan Megawati dan Jokowi Usai Kaesang...   ganjar   \n",
       "5  BEM FISIP Se-Surabaya Tantang 3 Capres Adu Gag...   ganjar   \n",
       "6  Ketum Projo Bocorkan Nama Capres yang Akan Did...   ganjar   \n",
       "7  Harapan Besar Pecinta Budaya Populer Indonesia...   ganjar   \n",
       "8  Jadi Ketua TPN Ganjar Pranowo, Arsjad Rasjid C...   ganjar   \n",
       "\n",
       "                     author               category  \\\n",
       "0  Marlinda Oktavia Erwanti                 Pemilu   \n",
       "1              Indra Komara                 Pemilu   \n",
       "2             Tara Wahyu NV                 Pemilu   \n",
       "3       Kadek Melda Luxiana                 Pemilu   \n",
       "4              Tim detikcom                 Pemilu   \n",
       "5             Esti Widiyana                 Berita   \n",
       "6             Tara Wahyu NV                 Berita   \n",
       "7        Atmi Ahsani Yusron            Berita Kpop   \n",
       "8            Anisa Indraini  Berita Ekonomi Bisnis   \n",
       "\n",
       "                            date  \\\n",
       "0  Selasa, 26 Sep 2023 09:25 WIB   \n",
       "1  Selasa, 26 Sep 2023 17:24 WIB   \n",
       "2  Selasa, 26 Sep 2023 15:29 WIB   \n",
       "3  Selasa, 26 Sep 2023 08:45 WIB   \n",
       "4  Selasa, 26 Sep 2023 09:03 WIB   \n",
       "5  Selasa, 26 Sep 2023 15:46 WIB   \n",
       "6  Selasa, 26 Sep 2023 14:51 WIB   \n",
       "7  Selasa, 26 Sep 2023 14:24 WIB   \n",
       "8  Selasa, 26 Sep 2023 09:10 WIB   \n",
       "\n",
       "                                             content  \\\n",
       "0  Ketua Tim Pemenangan Nasional (TPN) bakal calo...   \n",
       "1  Presiden Joko Widodo (Jokowi) mengingatkan kad...   \n",
       "2  Relawan pendukung Presiden Joko Widodo (Jokowi...   \n",
       "3  PPP meminta Ketum PDIP, Megawati Soekaroputri ...   \n",
       "4  Putra Presiden Joko Widodo (Jokowi), Kaesang P...   \n",
       "5  Badan Eksekutif Mahasiswa Fakultas Ilmu Sosial...   \n",
       "6  Projo, organisasi pendukung Presiden Joko Wido...   \n",
       "7  Muda-mudi Indonesia sedang bergelora dua tahun...   \n",
       "8  Ketua Umum Kamar Dagang dan Industri (KADIN) I...   \n",
       "\n",
       "                                                link  \n",
       "0  https://news.detik.com/pemilu/d-6950733/jadi-k...  \n",
       "1  https://news.detik.com/pemilu/d-6951804/jokowi...  \n",
       "2  https://news.detik.com/pemilu/d-6951509/projo-...  \n",
       "3  https://news.detik.com/pemilu/d-6950710/menerk...  \n",
       "4  https://news.detik.com/pemilu/d-6950719/soal-h...  \n",
       "5  https://www.detik.com/jatim/berita/d-6951552/b...  \n",
       "6  https://www.detik.com/jateng/berita/d-6951412/...  \n",
       "7  https://hot.detik.com/berita-kpop/d-6951328/ha...  \n",
       "8  https://finance.detik.com/berita-ekonomi-bisni...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'./excel/detik_{keywords}_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links=[]\n",
    "# # jumlah Page yang diambil \n",
    "# jumlah_index = 20\n",
    "\n",
    "# for index in range(jumlah_index):\n",
    "#     url = f\"https://news.detik.com/indeks/{index+1}\"  \n",
    "#     # print(url)\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#     articles = soup.find_all('article', {\"class\": \"list-content__item\"})\n",
    "    \n",
    "#     for article in articles:\n",
    "#         link = article.find('a')['href']\n",
    "#         links.append(link)\n",
    "    \n",
    "# print(\"Total Links\",len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = []\n",
    "# author = []\n",
    "# date = []\n",
    "# content = []\n",
    "# category =[]\n",
    "\n",
    "# for link in links:\n",
    "#     url = link\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "#     # Judul Berita\n",
    "#     title_elem = soup.find('h1', {\"class\": \"detail__title\"})\n",
    "#     if title_elem:\n",
    "#         title_text = title_elem.text.strip()\n",
    "#     else:\n",
    "#         title_text = \"Title not found\"\n",
    "#     title.append(title_text)\n",
    "    \n",
    "#     # Author berita\n",
    "#     author_elem = soup.find('div', {\"class\": \"detail__author\"})\n",
    "#     if author_elem:\n",
    "#         author_text = author_elem.get_text()\n",
    "#         author_text = author_text.split('-')[0].strip()\n",
    "#     else:\n",
    "#         author_text = \"Author not found\"\n",
    "#     author.append(author_text)\n",
    "    \n",
    "#     # tanggal berita\n",
    "#     date_elem = soup.find('div', {\"class\": \"detail__date\"})\n",
    "#     if date_elem:\n",
    "#         date_text = date_elem.text.strip()\n",
    "#     else:\n",
    "#         date_text = \"Date not found\"\n",
    "#     date.append(date_text)\n",
    "    \n",
    "#     # Category berita\n",
    "#     category_elements = soup.find('div',{\"class\": \"page__breadcrumb\"})\n",
    "#     if category_elements:\n",
    "#         category_text = category_elements.find('a',{\"dtr-sec\": \"breadcrumbkanal\"})\n",
    "#         category_text= category_text.text.strip()\n",
    "#     else:\n",
    "#         category_text = \"Category not found\"\n",
    "#     category.append(category_text)\n",
    "   \n",
    "    \n",
    "#     # Content Berita\n",
    "#     body_elem = soup.find('div', {\"class\": \"detail__body\"})\n",
    "    \n",
    "#     if body_elem:\n",
    "#         content_elem = body_elem.find_all('p')\n",
    "#         content_text = \"\"\n",
    "#         for p in content_elem:\n",
    "#             content_text += p.text.strip() + \"\\n\"\n",
    "        \n",
    "#         if content_text.strip():\n",
    "#             content.append(content_text)\n",
    "#         else:\n",
    "#             content.append(\"Content not found\")\n",
    "#     else:\n",
    "#         content.append(\"Content not found\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {'title': title,\n",
    "#         'author' : author,\n",
    "#         'category':category,\n",
    "#         'date': date,\n",
    "#         'content' : content,\n",
    "#         'link' : links\n",
    "#         }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to ./excel/detik_2023-09-26_17-27-53.xlsx\n"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "excel_file_name = f'./excel/detik_{current_datetime}.xlsx'\n",
    "df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "print(f'Data has been saved to {excel_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Latihan Pengecek dan find element\n",
    "# url = f\"https://news.detik.com/detiknews/d-6948823/siskaeee-penuhi-panggilan-polisi-soal-film-porno-ini-penampilannya\"  \n",
    "# # print(url)\n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "# Category\n",
    "# category_elements = soup.find('div',{\"class\": \"page__breadcrumb\"})\n",
    "# print(category_elements)\n",
    "# category_text = category_elements.find('a',{\"dtr-sec\": \"breadcrumbkanal\"})\n",
    "# print(category_text.text.strip())\n",
    "\n",
    "# ambil author detik\n",
    "# title_elem = soup.find('div', {\"class\": \"detail__author\"})\n",
    "# author_text = title_elem.get_text()\n",
    "# author_name = author_text.split('-')[0].strip()\n",
    "# print(author_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_url(url):\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code == 200:\n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#     else:\n",
    "#         print(f\"Failed to retrieve data from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls = ['https://kompas.com', 'https://kompas.com', 'https://kompas.com']\n",
    "# threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url in urls:\n",
    "#     thread = threading.Thread(target=scrape_url, args=(url,))\n",
    "#     thread.start()\n",
    "#     threads.append(thread)\n",
    "\n",
    "# print(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for thread in threads:\n",
    "#     thread.join()\n",
    "    \n",
    "# print(\"All threads finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
