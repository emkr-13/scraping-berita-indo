{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/11/2023\n"
     ]
    }
   ],
   "source": [
    "date='2023-11-01'\n",
    "format=datetime.strptime(date, \"%Y-%m-%d\")\n",
    "# print(format)\n",
    "formatted_date_string = format.strftime(\"%d/%m/%Y\")\n",
    "print(formatted_date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = {\n",
    "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "#     }\n",
    "# url = f\"https://www.inews.id/indeks/all/01-11-2023/2\"\n",
    "# response = requests.get(url, headers=headers)\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# articles = soup.find_all('li', {\"class\": \"padding-10px-all\"})\n",
    "# for article in articles:\n",
    "#     link = article.find('a')['href']\n",
    "#     print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(date,page_number):\n",
    "    format=datetime.strptime(date, \"%Y-%m-%d\")\n",
    "# print(format)\n",
    "    formatted_date_string = format.strftime(\"%d-%m-%Y\")\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = f\"https://www.inews.id/indeks/all/{formatted_date_string}/{page_number}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('li', {\"class\": \"padding-10px-all\"})\n",
    "    links = []\n",
    "    for article in articles:\n",
    "        link = article.find('a')['href']\n",
    "        links.append(link)\n",
    "    print(f\"Scraped {len(links)} links from page {page_number} url {url}\")\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_link_per_day(date, max_threads=5):\n",
    "    page_number = 1\n",
    "    page_links = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:\n",
    "        futures = []\n",
    "\n",
    "        while True:\n",
    "            future = executor.submit(scrape_links, date, page_number)\n",
    "            futures.append(future)\n",
    "            page_number += 1\n",
    "\n",
    "            # Break the loop if no more articles are found\n",
    "            if not future.result():\n",
    "                break\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            page_links.extend(future.result())\n",
    "\n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 30 links from page 1 url https://www.inews.id/indeks/all/01-11-2023/1\n",
      "Scraped 30 links from page 2 url https://www.inews.id/indeks/all/01-11-2023/2\n",
      "Scraped 30 links from page 3 url https://www.inews.id/indeks/all/01-11-2023/3\n",
      "Scraped 30 links from page 4 url https://www.inews.id/indeks/all/01-11-2023/4\n",
      "Scraped 30 links from page 5 url https://www.inews.id/indeks/all/01-11-2023/5\n",
      "Scraped 30 links from page 6 url https://www.inews.id/indeks/all/01-11-2023/6\n",
      "Scraped 30 links from page 7 url https://www.inews.id/indeks/all/01-11-2023/7\n",
      "Scraped 30 links from page 8 url https://www.inews.id/indeks/all/01-11-2023/8\n",
      "Scraped 30 links from page 9 url https://www.inews.id/indeks/all/01-11-2023/9\n",
      "Scraped 30 links from page 10 url https://www.inews.id/indeks/all/01-11-2023/10\n",
      "Scraped 30 links from page 11 url https://www.inews.id/indeks/all/01-11-2023/11\n",
      "Scraped 30 links from page 12 url https://www.inews.id/indeks/all/01-11-2023/12\n",
      "Scraped 30 links from page 13 url https://www.inews.id/indeks/all/01-11-2023/13\n",
      "Scraped 30 links from page 14 url https://www.inews.id/indeks/all/01-11-2023/14\n",
      "Scraped 30 links from page 15 url https://www.inews.id/indeks/all/01-11-2023/15\n",
      "Scraped 18 links from page 16 url https://www.inews.id/indeks/all/01-11-2023/16\n",
      "Scraped 0 links from page 17 url https://www.inews.id/indeks/all/01-11-2023/17\n"
     ]
    }
   ],
   "source": [
    "link=scrape_link_per_day('2023-11-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url,max_retries=2):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "            try:\n",
    "                headers = {\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "                }\n",
    "                response = requests.get(url, headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                    \n",
    "                    \n",
    "                    # Judul Berita\n",
    "                    title_elem = soup.find('h1', {\"style\": \"padding:0 0 10px; margin:0; font-weight:700; font-size:34px; color:#000;\"})\n",
    "                    if title_elem:\n",
    "                        title_text = title_elem.text.strip()\n",
    "                    else:\n",
    "                        title_text = \"Title not found\"  \n",
    "                    # tanggal berita\n",
    "                    date_elem = soup.find('a', {\"class\": \"author-profile\"})\n",
    "                    # print(date_elem)\n",
    "                    if date_elem:\n",
    "                        date_text= date_elem.text.strip()\n",
    "                        date_text= date_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "                        date_text=' '.join(date_text.split())\n",
    "                        match = re.search(r'\\b(\\d{2} \\w+ \\d{4})', date_text)\n",
    "                        if match:\n",
    "                            extracted_date_str = match.group(1)\n",
    "                        date_object = datetime.strptime(extracted_date_str, '%d %B %Y')\n",
    "                        formatted_date = date_object.strftime('%Y-%m-%d')\n",
    "                        # date_text = date_text\n",
    "                    else:\n",
    "                        date_text = \"Date not found\"\n",
    "                    #     # Content Berita\n",
    "                    body_elem = soup.find('div', {\"itemprop\": \"articleBody\"})\n",
    "                        \n",
    "                    if body_elem:\n",
    "                        content_elem = body_elem.find_all('p')\n",
    "                        content_text = \"\"\n",
    "                        for p in content_elem:\n",
    "                                content_text += p.text.strip() + \"\\n\"\n",
    "                            \n",
    "                        if content_text.strip():\n",
    "                            content_text=content_text\n",
    "                            content_text = content_text.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "                            content_text = ' '.join(content_text.split())\n",
    "                        else:\n",
    "                            content_text=\"Content not found\"\n",
    "                    else:\n",
    "                            content_text=\"Content not found\"\n",
    "\n",
    "                    return{\n",
    "                        'title': title_text,\n",
    "                        'date': formatted_date,\n",
    "                        'content':content_text,\n",
    "                        'link' : url}\n",
    "                elif response.status_code == 429:\n",
    "                    print(f\"Received a 429 error for {url}. Retrying in 5 seconds...\")\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve data from {url}: Status Code {response.status_code}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching URL '{url}': {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL '{url}': {e}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(f\"Retrying {url} (Attempt {retries}/{max_retries})\")\n",
    "                time.sleep(5)  # You can adjust the delay as needed\n",
    "    return None         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.inews.id/news/nasional/relawan-garuda-dukung-ganjar-pranowo-mahfud-md-pilihan-terbaik'\n",
    "data_inews = scrape_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Relawan Garuda Dukung Ganjar Pranowo-Mahfud MD: Pilihan Terbaik!', 'date': '2023-11-01', 'content': 'JAKARTA, iNews.id - Ratusan aktivis mahasiswa dan alumni dari Kelompok Cipayung yang tergabung dalam Relawan Garuda mendeklarasikan dukungan untuk pasangan Ganjar Pranowo dan Mahfud MD, Rabu (1/11/2023). Dukungan ditegaskan khususnya setelah muncul putusan Mahkamah Konstitusi (MK) yang kontroversial.\"Awal-awal kami masih bicara tentang dukungan pada Ganjar, tetapi kita tidak mau membentuk relawan karena sudah banyak relawan yang juga deklarasi. Tetapi tiba-tiba ada tsunami politik lewat operasi politik yang ada di MK, akhirnya kita tersentak,\" kata Koordinator Nasional Relawan Garuda Dikson Siringo-ringo di Yogyakarta, dikutip dari keterangan resmi.Terkait dengan moralitas dan etika politik, Dikson menilai pasangan Ganjar dan Mahfud merupakan tokoh yang menjunjung tinggi tentang kedua hal itu. Rekam jejak Ganjar dan Mahfud, kata Dikson, telah membuktikan itu.Menurut Dikson, Ganjar-Mahfud adalah tokoh yang bisa dipercaya untuk melanjutkan masa depan Indonesia.\"Kami mendukung Ganjar dan Mahfud, karena itu pilihan yang paling waras untuk mempercayakan bagaimana masa depan politik Indonesia agar diurus oleh orang yang baik, kredibel dan kompeten. Kita tidak ragu kepada dua figur itu,\" kata Dikson.\"Tidak ada alasan lain untuk tidak mendukung Ganjar-Mahfud, karena dari segi latar belakang, pengalaman, rekam jejak, kompetensi saya kira pilihan terbaik ya pasangan Ganjar-Mahfud,\" imbuhnya. Lihat juga: Video Akting Adegan Dilan, Mirip Banget AslinyaEditor : Reza FajriHalaman Selanjutnya Halaman : 1 2 Follow Berita iNews di Google NewsTAG : ganjar pranowo mahfud md mahkamah konstitusi Ganjar Mahfud Bagikan Artikel:Editor : Reza FajriFollow Berita iNews di Google NewsBagikan Artikel:', 'link': 'https://www.inews.id/news/nasional/relawan-garuda-dukung-ganjar-pranowo-mahfud-md-pilihan-terbaik'}\n"
     ]
    }
   ],
   "source": [
    "print(data_inews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
